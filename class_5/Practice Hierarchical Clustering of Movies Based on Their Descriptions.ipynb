{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**\n",
    " \n",
    "Reset the Python environment to clear it of any previously loaded variables, functions, or libraries. Then, import the libraries needed to complete the code Professor Melnikov presented in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from IPython.core.interactiveshell import InteractiveShell as IS\n",
    "IS.ast_node_interactivity = \"all\"    # allows multiple outputs from a cell\n",
    "import pandas as pd, numpy as np, seaborn as sns, matplotlib.pyplot as plt, collections, re, json\n",
    "from sentence_transformers import SentenceTransformer  # encodes text documents to 768D vectors\n",
    "pd.set_option('max_rows', 5, 'max_columns', 20, 'max_colwidth', 100, 'precision', 2) # define Pandas table format for print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n",
    "\n",
    "# **Review**\n",
    "\n",
    "Review the code Professor Melnikov used to build two clusters of movies. Movies are automatically assigned to one of these clusters based on their numeric vector representation of their textual descriptions. These auto-labels can be compared to expert-assigned movie genres.\n",
    "\n",
    "Changes from the video:\n",
    "\n",
    "1. Encoding all 4803 movie descriptions takes about 10+ minutes, but only 65 movies (with different genres) are used in clustering. So, instead, the filtering by genre is applied. Then encoding 65 movies takes about five to 10 seconds.\n",
    "\n",
    "2. A much smaller sentence transformer model is used (50MB instead of 330MB). More details are below.\n",
    "\n",
    "\n",
    "First, some objects are needed to parse and encode movie descriptions.\n",
    "\n",
    "\n",
    "## **Build JSON Parser**\n",
    "\n",
    "As in the previous notebook, the code below defines the `JSON_Values()` UDF, which takes a string of list-like [JSON](https://www.json.org/json-en.html) objects and retrieves values associated with the key `'name'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JSON_Values(sJSONs, sKey='name', asString=True, sep=', '):\n",
    "    # Convert: '[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso_639_1\": \"es\", \"name\": \"Español\"}]' --->>> ['English', 'Español']\n",
    "    sJSONs = re.sub('[\\[\\]]', '', sJSONs)   # remove square brackets in a string\n",
    "    LsJSONs = re.sub('}, {', '}|{', sJSONs).split('|')   # relace comma with a pipe character separating JSON\n",
    "    try:    LsValues = [json.loads(s)[sKey] for s in LsJSONs]   # in case of an error, use empty list\n",
    "    except: LsValues = []\n",
    "    return sep.join(LsValues) if asString else LsValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Movie Attributes**\n",
    "\n",
    "The parser will be used to retrieve multiple genres and other textual attributes for select movies in The Movie Database ([TMDB](https://www.themoviedb.org/)), which contains 4803 movies (rows) and 19 features (columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://raw.githubusercontent.com/omelnikov/data/main/TMDB/138_4508_compressed_tmdb_5000_movies.csv.zip\n",
    "dfAll = pd.read_csv('movies.zip').fillna('').set_index('original_title')\n",
    "print(f'df.shape = {dfAll.shape}')\n",
    "dfAll[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Parse Out Movie Genres**\n",
    "\n",
    "Next, `JSON_Values()` is applied to each text of genre value to extract genre names for each movie. These will be compared with the genres automatically determined by the clustering algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGenresClean = dfAll.genres.apply(lambda x: JSON_Values(x, sep=', ')).to_frame()\n",
    "dfGenresClean.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Build Distribution of Genres**\n",
    "\n",
    "The following few cells retrieve all movie genres and compute frequncies for each unique genre. You could expect the most dominant genres (i.e., drama and comedy) to drive the estimated genres in clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sGenres = ', '.join(dfGenresClean.genres.values)  # a string of (duplicated and comma-separated) genres of all movies\n",
    "sGenres[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The genre frequencies are shown below. Naturally, each movie is likely to contribute to several counts in this table, since each movie has multiple expert-assigned genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGenresStats = pd.DataFrame(collections.Counter(sGenres.split(', ')).most_common(), columns=['Genre', 'Non-disjoint counts']).set_index('Genre').T\n",
    "dfGenresStats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Select Movies With Disjoint Genres**\n",
    "\n",
    "You can evaluate whether the expert-assigned genres are reasonable by subjectively evaluating movies in a particular genre or in a particular combination of genres. Such genre combinations can be built with Boolean masks (filters), i.e., vectors of zeros and ones indicating whether to include the movie in the combination.\n",
    "\n",
    "A dictionary of masking arrays, `DvMasks`, is built below. It can be used to construct any complex filter of genres. `DvMasks` contains 21 genres as keys and each genre contains 4803 Boolean values (one for each movie), indicating whether the movie has that genre or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DvMasks = {g:dfAll.genres.str.contains(g).values for g in dfGenresStats if g} # dictionary of masking arrays for genres\n",
    "print(f'len(DvMasks[\"War\"]) = {len(DvMasks[\"War\"])}; ', DvMasks[\"War\"]) # masking vector for genre War\n",
    "DvMasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, \n",
    "1. a mask `vMaskA` is built for animations/family/comedy/fantasy films, and \n",
    "1. a mask `vMaskW` is built for western/action films\n",
    "1. masks `vMaskAnW` and `vMaskWnA` are built to mutually exclude `vMaskA` from `vMaskW` and vice versa\n",
    "1. a mask `vMaskAW` combines two disjoint masks `vMaskAnW` and `vMaskWnA`. It is used to filter the rows of the dataframe of all 4803 movies, `dfAll`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vMaskA = DvMasks['Animation'] & DvMasks['Family'] & DvMasks['Comedy'] & DvMasks['Fantasy'] # combination of genres\n",
    "vMaskW = DvMasks['Western']   & DvMasks['Action']\n",
    "vMaskAnW = vMaskA & ~ vMaskW    # mask vector (of Booleans) for movies in genres 1, not in genres 2\n",
    "vMaskWnA = vMaskW & ~ vMaskA\n",
    "vMaskAW = vMaskAnW | vMaskWnA   # mask vector with the union of movies with either genres 1 or 2 \n",
    "# dfAW, dfEmbAW = df[vMaskAW], dfEmb[vMaskAW]\n",
    "df = dfAll[vMaskAW]\n",
    "print(f'# GenreA = {sum(vMaskAnW)}; # GenreW = {sum(vMaskWnA)}; # GenreAW = {sum(vMaskAW)}') # counts (= sums of ones)\n",
    "vMaskAW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to movie experts, each of the movies below is either a western/action or animations/family/comedy/fantasy, but not both (by design of `vMaskAW`). The genre classification appears reasonable, but some movies appear to be misclassified. For example, arguably *Monster House* may not be a fantasy film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.title.tolist()[:20])   # final spot check of movies: do they look relevant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88dbb9667f7e39d8bcf24691f219a3a0",
     "grade": false,
     "grade_id": "cell-fdc14fec6dd60c33",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## **Build More Complete Movie Descriptions**\n",
    "\n",
    "As in the previous notebook, the code below builds movie vectors from concatenated textual attributes, which are passed through the [SBERT](https://www.sbert.net/) sentence encoding model. Descriptive textual fields are first cleaned up using the `JSON_Values()` function and then concatenated with a space separator.\n",
    "\n",
    "<strong>Note:</strong> Movie genres are specifically left out from the `Desc` field because our model needs to identify genres automatically based on the provided movie description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToStr = lambda pdSeries: ' ' + pdSeries.apply(JSON_Values)\n",
    "dfMov = (df.title  + ' ' + df.tagline + ' ' + df.overview + \\\n",
    "         ToStr(df.keywords) + ToStr(df.production_countries)).to_frame().rename(columns={0:'Desc'})\n",
    "dfMov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Encode Movie Descriptions**\n",
    "\n",
    "The next code cell loads a pretrained language model and applies it to encode each movie's textual description created in the cell above. Encoding descriptions of ~5K movie descriptions may take 10+ minutes, but encoding 65 descriptions takes a few seconds.\n",
    "\n",
    "<strong>Note:</strong> In the previous video, Professor Melnokiv used the `paraphrase-distilroberta-base-v1` (330 MB) model. In this activity, you will use a smaller model, `paraphrase-albert-small-v2` (~50 MB), which encodes any sized text into a 768-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 5, 'max_columns', 10, 'precision', 2)\n",
    "%time SBERT = SentenceTransformer('paraphrase-albert-small-v2')  # load a pre-trained language model\n",
    "%time mEmb = SBERT.encode(dfMov.Desc.tolist()) # embedding may take 4-7 minutes for ~5K descriptions\n",
    "dfEmb = pd.DataFrame(mEmb, index=df.title)\n",
    "dfEmb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Clustering Movies**\n",
    "\n",
    "Classifying content is a laborious task that requires many hours of expensive experts' work. This is why you want an algorithm that can do most of the work or at least assign preliminary genres for experts to review later. \n",
    "\n",
    "Below is a hierarchical model, which attempts to cluster movies into two groups based on their descriptions. At first, an object is instantiated from the `AgglomerativeClustering` class. It is then fitted on the encoded representations of movie descriptions. The focus is on the few movies selected above, which is easier to interpret and avoids messy overplotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "# ?AgglomerativeClustering   # to view help manual\n",
    "hac = AgglomerativeClustering(n_clusters=2) # number of desired clusters to find\n",
    "hac.fit(dfEmb)    # build a hierarchical tree and assign cluster labels to movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can draw the estimated cluster assignments via attribute `labels_`. These labels are numbers from 0 to `n_clusters-1`. Since only two clusters were specified, each movie vector is assigned to either cluster 0 or cluster 1. Note that the algorithm does not know what \"action\" or \"animation\" is. It simply looks for movie vectors located close by in a 768-dimensional vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGenresClean = dfGenresClean.genres[vMaskAW]   # pandas Series object with selected movies and their genres\n",
    "pd.DataFrame(dict(cluster=hac.labels_, genres=SGenresClean), index=df.title).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Converting Movie Vectors to a Low Dimensional Representation (for Plotting)**\n",
    "\n",
    "If you want to plot the movie vectors on a 2D plane, then you need to  convert each 768D vector into a 2D representation. Principal component analysis (PCA) is a popular choice. It uses singular value decomposition (SVD) as its engine to find a new set of 768 axes along the most-explanatory (i.e., most variable) directions of the given vectors. Then two top axes (or coordinates) can be plotted and other 766 coordinates are dropped as least explanatory (of the underlying distribution pattern).\n",
    "\n",
    "While the theory behind PCA may seem cumbersome, its implementation is straightforward. As usual, a call to `PCA()` creates an object, which can be fitted to the existing set of 768D vectors. To avoid computing unneeded coordinates, one can specify `n_components=2` to compute only the top (i.e., most \"important\") components in the new coordinate system. Below these coordinates are named as $x$ and $y$ and labels are assigned to each new representation of a movie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA   # PCA uses SVD to reduce dimensionality of the feature space\n",
    "# ?PCA    # to view help manual\n",
    "mPC12 = PCA(n_components=2).fit_transform(dfEmb)   # project 768-dim vectors to 2D space for plotting\n",
    "dfPC12 = pd.DataFrame(mPC12, columns=['x','y'], index=df.title)\n",
    "dfPC12['cluster'] = hac.labels_     # retrieve learnt cluster labels\n",
    "dfPC12                            # contains new (x,y) coordinates and cluster labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generating RGB Colors for Each Movie**\n",
    "\n",
    "Now you are ready to plot each movie as a colored dot indicating the cluster it belongs to. For that, `sns.color_palette()` is used to convert label values 0 and 1 to some RGB (red, green and blue) color representations. `vColors` is a vector containing RGB colors corresponding to each movie in `dfPC12` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go               # import graph object from plotly library\n",
    "sPlotTtl = 'Clusters identified by Hierarhichal Clusterning Algorithm'\n",
    "LsPalette = [f'rgb({c[0]},{c[1]},{c[2]})' for c in sns.color_palette('bright', hac.n_clusters)]  # strings of RGB color values\n",
    "vColors = np.array(LsPalette)[dfPC12.cluster]   # vector of colors (as RGB string) for each point \n",
    "vColors[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Plotting Clusters of Movies**\n",
    "\n",
    "Finally, the selected movies are plotted in 2D plane in red/blue colors, which are assigned according to the identified cluster labels. The coordinate axes are the top two principal components (PCs). As expected, the clusters are mostly separated with some films in the overlap area identified as being somewhat belonging to both groups. \n",
    "\n",
    "[Plotly](https://plotly.com/python/) package allows you to create dynamically appearing labels/markers over the plotted points, so you can hover the mouse over a point to find out its movie title and its genres. While learning the plotly package is beyond the scope of this course, you can further investigate its powerful capacity.\n",
    "\n",
    "Notably, the clustering algorithm was able to fairly well identify two major movie types. The blue dots are mostly animations and the red dots are mostly action movies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sMovieGenres = [a + '; ' + b for a,b in zip(dfPC12.index, SGenresClean)] # point labels with title+genre\n",
    "DMarkers = dict(size=5, line=dict(width=1, color=vColors), color=vColors)\n",
    "goMargin = go.layout.Margin(l=0, r=0, b=0, t=0)\n",
    "goS = go.Scatter(x=dfPC12.x, y=dfPC12.y, mode='markers', marker=DMarkers, text=sMovieGenres);\n",
    "print(sPlotTtl)\n",
    "goLayout = go.Layout(hovermode='closest', margin=goMargin, width=1000, \n",
    "                   height=300, xaxis={'title':'PC1'}, yaxis={'title':'PC2'});\n",
    "\n",
    "fig = go.Figure(layout=goLayout)  # prepare a figure with specified layout\n",
    "fig.add_trace(goS)                # add points to canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d82067d50e5d1df18016906a30e1e44",
     "grade": false,
     "grade_id": "cell-defc94112170e7dc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n",
    "\n",
    "# **Optional Practice**\n",
    "\n",
    "Now you will practice clustering movie vectors.\n",
    "\n",
    "As you work through these tasks, check your answers by running your code in the *#check solution here* cell, to see if you’ve gotten the correct result. If you get stuck on a task, click the **See solution** drop-down to view the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Use `AgglomerativeClustering()` to create an object named`hac3` with three clusters. Then fit it on `dfEmbAW` and print all labels.\n",
    "\n",
    "<b>Hint:</b> Use the code from the video to create <code>hac3</code> object with <code>AgglomerativeClustering(n_clusters=3)</code> command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details><summary><font color=#B31B1B>▶ </font>See <b>solution</b>.</summary>\n",
    "<pre class=\"ec\">\n",
    "hac3 = AgglomerativeClustering(n_clusters=3) # number of desired clusters to find\n",
    "hac3.fit(dfEmb)    # build a hierarchical tree and assign cluster labels to movies\n",
    "hac3.labels_\n",
    "</pre>\n",
    "</details> \n",
    "</font>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Use labels from `hac3` to label all movies in `SGenresClean` Pandas Series. Then print out the smallest cluster. How are these movies similar to each other and different from movies in the remaining two clusters?\n",
    "\n",
    "<b>Hint:</b> You can simply observe the printed labels 0, 1, and 2 in Task 1 to decide which label corresponds to the smallest cluster. Then filter the Series object on this cluster ID, for example, using <code>.query('cluster==?')</code> method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details><summary><font color=#B31B1B>▶ </font>See <b>solution</b>.</summary>\n",
    "<pre class=\"ec\">\n",
    "df3 = pd.DataFrame(dict(cluster=hac3.labels_, genres=SGenresClean), index=df.title)\n",
    "df3.query('cluster==2')\n",
    "</pre>\n",
    "</details> \n",
    "</font>\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
