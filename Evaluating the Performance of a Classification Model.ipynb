{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a7ed38627cace6a1296aebfb2ea8959",
     "grade": false,
     "grade_id": "cell-f62b1cd173d0c12c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# **Part Three of the Course Project**\n",
    "In this part of the course project, you will train and evaluate your models using the Area Under the ROC Curve metric.\n",
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**\n",
    " \n",
    "Reset the Python environment to clear it of any previously loaded variables, functions, or libraries. Then, import the libraries needed to complete this part of the course project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a177ce89449e74154a04802270e79acb",
     "grade": false,
     "grade_id": "cell-1045e4f3a50b7bf1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from IPython.core.interactiveshell import InteractiveShell as IS\n",
    "IS.ast_node_interactivity = \"all\"    # allows multiple outputs from a cell\n",
    "import pandas as pd, numpy as np, seaborn as sns, matplotlib.pyplot as plt, nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter\n",
    "from numpy.testing import assert_equal as eq, assert_almost_equal as aeq\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import unittest\n",
    "from colorunittest import run_unittest\n",
    "CosSim = lambda x, y: x @ y / (x @ x)**0.5 / (y @ y)**0.5  # our own implementation of cosine similarity\n",
    "pd.set_option('max_colwidth', 100, 'display.max_rows', 4)\n",
    "\n",
    "_ = nltk.download(['names'], quiet=True)\n",
    "LsM = nltk.corpus.names.words('male.txt')   # list of strings: male names\n",
    "LsF = nltk.corpus.names.words('female.txt') # list of strings: female names\n",
    "LsF = [n for n in LsF if n not in LsM]      # remove 365 female names that match male names\n",
    "print(f'{len(LsM)} male names:  ', LsM[:8])\n",
    "print(f'{len(LsF)} female names:', LsF[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef3e8dced424f8e13dcc01c2fbda9d42",
     "grade": false,
     "grade_id": "cell-ad6dbb51a6dd6031",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Overview\n",
    "\n",
    "The classes are somewhat imbalanced, since there are not an equal number of observations in each class. There are about 63% of female names and 37% of male names. So, if you randomly draw a name, it will turn out to be a female's name 63% of the time. Thus, a naive model that randomly draws a name and ignorantly classifies it as a female name will be correct 63% of the time. Consequently, you should use confusion matrix and related metrics to more informatively assess the quality of our model.\n",
    " \n",
    "In this project, you will engineer features based on 50 word2vec coefficients. Then you will build a logistic regression and evaluate its quality with metrics from a confusion matrix. One caveat is that not all names (even if lowercase) are in the word2vec model. So, you'll build a function to draw character-level vectors and aggregate these to word-level vectors with the hope that some vowel and consonant information of the characters in a word will still be useful in your model and you would not need to drop words not found in word2vec vocabulary.\n",
    "\n",
    "\n",
    "Do not sort or reorder observations unless instructed to do so. The tests assume the continuity in the order of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "449e2224ab2cee954eae142bf07bc425",
     "grade": false,
     "grade_id": "cell-0b70432ea3440df7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)  # seed random number generator with a number 0 (for reproducibility)\n",
    "# LsF = sorted(list(rng.choice(LsF, size=len(LsM), replace=False)))       # shorten the list of female names\n",
    "df = pd.DataFrame(dict(Name=LsF + LsM, Y=[1]*len(LsF) + [0]*len(LsM)) ) # assign labels: 1=female, 0=male\n",
    "df.Name = df.Name.str.lower()   # convert all names to lower case\n",
    "df.set_index('Name', inplace=True)\n",
    "df.T                # display names (as column names) and their labels (0=male, 1=female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd5559b67d1b039845a4285bcf13ba90",
     "grade": false,
     "grade_id": "cell-3f8c25e153896f93",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Next, you load the word2vec model with 400K word vocabulary of words mapped to 50-dimensional vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d6bd9e4fb9465b180b88705fdacb3d4",
     "grade": false,
     "grade_id": "cell-66de273dbf92c912",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%time wv = KeyedVectors.load_word2vec_format('glove-wiki-gigaword-50.gz')  # ~20 seconds to load this model\n",
    "wv['abagail']    # retrieve a word vector for the name abagail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6450a79c09f227a4a0c5ce5b13c08e22",
     "grade": false,
     "grade_id": "Task1_read",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Task 1. A Word Vector From Characters\n",
    " \n",
    "Create a `CharVec()` function which takes a word (as a string of characters) and generates a word vector, which is a centroid of all character-level vectors found in the model `wv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89d75abc943550855e11a5b55ccfcd3b",
     "grade": false,
     "grade_id": "Task1_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def CharVec(w:'string'='abagael', wv:'word2vec model'=wv) -> np.zeros(50):\n",
    "    '''Takes a word w and word2vec model wv. \n",
    "    Then for each character of w we retrieve a word vector if a character is found in wv.\n",
    "    Finally, all 50-dim character vectors are averaged with np.mean()\n",
    "    to produce a 50-dim word vector. Characters not found in wv are ignored\n",
    "    Return: 50-dim word vector. If no characters are found in wv, then 50-dim zero vector is returned.'''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return word_vector  # numpy array of length 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ece62b5610bdca37db19b21d092eff26",
     "grade": true,
     "grade_id": "Task1_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST & AUTOGRADE CELL\n",
    "@run_unittest\n",
    "class test_task_1(unittest.TestCase):\n",
    "    def test_00(self): aeq(CharVec('a')[:5], [.217, .465, -0.468, .101, 1.013], decimal=3)\n",
    "    def test_01(self): aeq(CharVec('a').sum(), 1.6782844, decimal=3)\n",
    "    def test_02(self): eq(CharVec('A'), np.zeros(50))\n",
    "    def test_03(self): aeq(CharVec('abc')[:5], [-.191, .426, .049, .636, .89], decimal=3)\n",
    "    def test_04(self): aeq(CharVec('abc').sum(), 8.53262, decimal=3)\n",
    "    def test_05(self): aeq(CharVec('abagail').sum(), 4.7599854, decimal=3)\n",
    "    def test_06(self): aeq(CharVec('Abbe').sum(), 8.714625, decimal=3)\n",
    "    def test_07(self): aeq(CharVec('marco-pollo').sum(), 4.661618, decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1fffc6c00c8340d750998835fda8618",
     "grade": false,
     "grade_id": "Task2_read",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Task 2. A Word Vector For Any Word\n",
    "\n",
    "Next, create a `W2V()` function, which returns a word vector, if one is found. Otherwise, it makes a call to `CharVec()` function to build a new vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd799ef6be5e5c38ac3690a9c0c9bfb9",
     "grade": false,
     "grade_id": "Task2_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def W2V(w:'string'='abagail', wv:'word2vec model'=wv) -> np.zeros(50):\n",
    "    '''W2V takes a word w and a word2vec model wv. \n",
    "    If w is in the model wv, its vector is returned. \n",
    "    Otherwise, we call CharVec on w to build a new vector from its characters.\n",
    "    Returns: 50-dim word vector'''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return word_vector    # numpy array of length 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7237b985dcb8b55585c45437dd80fb1",
     "grade": true,
     "grade_id": "Task2_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST & AUTOGRADE CELL\n",
    "@run_unittest\n",
    "class test_task_2(unittest.TestCase):\n",
    "    def test_00(self): aeq(W2V('a')[:5], [.217, .465, -0.468, .101, 1.013], decimal=3)\n",
    "    def test_01(self): aeq(W2V('a').sum(), 1.6782844, decimal=3)\n",
    "    def test_02(self): eq(W2V('A'), np.zeros(50))\n",
    "    def test_03(self): aeq(W2V('abc')[:5], [.12305, .1083, .40415, 1.0219, .085337], decimal=3)\n",
    "    def test_04(self): aeq(W2V('abc').sum(), 2.0375853, decimal=3)\n",
    "    def test_05(self): aeq(W2V('abagail').sum(), 2.756581, decimal=3)\n",
    "    def test_06(self): aeq(W2V('Abbe').sum(), 8.714625, decimal=3)\n",
    "    def test_07(self): aeq(W2V('marco-pollo').sum(), 4.661618, decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice With Pandas: DataFrame() and concat()\n",
    "\n",
    "If you are already familiar with these Pandas functions, you can skip to Task 3.\n",
    "\n",
    "The Pandas `DataFrame()` function allows you to convert properly structured data in other formats into a Pandas DataFrame. For example, create a simple list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prac_lists = [[1, 2, 3],[2, 3, 4],[3, 4, 5],[4, 5, 6]]\n",
    "prac_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set is structured such that it is equivalent to a table with four rows and three columns. Pandas can easily convert this into a DataFrame as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prac_df_nums = pd.DataFrame(prac_lists)\n",
    "prac_df_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `DataFrame()` function automatically generated a new index (numbered 0 through 4) and column labels (numbered 0 through 2). \n",
    "\n",
    "Next, subset the `df` DataFrame so that it has the same number of rows as `prac_df_nums`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prac_df_names = df[:4]\n",
    "prac_df_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this DataFrame uses the **Name** column as its index (i.e., there are no numbers to the left of the **Name** column) and the other column has been given a non-default label as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prac_df_names.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change the default index during DataFrame creation by specifying the values you want to use, which do not need to be in data being converted to a DataFrame. An example of this would be the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prac_df_nums = pd.DataFrame(prac_lists, index = prac_df_names.index)\n",
    "prac_df_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can combine the data in these DataFrames using the Pandas `concat()` function. Please note that the order of the DataFrames listed in the function matters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prac_df_combined = pd.concat([prac_df_names,prac_df_nums])\n",
    "prac_df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this did combine the two DataFrames, but not exactly as desired. This is because the default behavior for the `concat()` function is to stack DataFrames vertically (across axis 0), on top of each other. Pandas will add both columns and rows to make this work, however if you want to stack horizontally, you need to specify axis = 1 as part of your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prac_df_combined = pd.concat([prac_df_names,prac_df_nums], axis = 1)\n",
    "prac_df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prac_df_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to experiment with these small sample DataFrame and familiarize yourself with these functions prior to attempting the next task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98a39073617be2516eac2b949d33e471",
     "grade": false,
     "grade_id": "Task3_read",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Task 3. Add Word Vector Features\n",
    "\n",
    "As a first step, copy `df` dataframe to another DataFrame named `df1` to preserve the original. Then convert each name in `df1.index` to its word vector using `W2V()` function and convert this to its own DataFrame. Finally, combine this DataFrame containing the resulting coefficients with the `df1` DataFrame, keeping the name of the DataFrame as `df1` and preserving the **Name** column as the index. The resulting DataFrame should contain the original DataFrame of names and labels plus 50 numeric values which are saved in columns named 0 to 49. Here is a small example of the resulting `df1`:\n",
    "\n",
    "|Name|Y|0|1|2|3|\n",
    "|-|-|-|-|-|-|\n",
    "|abagael|1|.074134|.662556|.229403|.64297|\n",
    "|abagail|1|-.537140|.313840|-.677850|-.53706|\n",
    "\n",
    "**Note: The line of code at the bottom of the task block should print output that matches what you see above. In addition, this and all other remaining tasks in this exercise can be written as a script cell rather than a function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff0ede12e9e46fb2c369c61852817f04",
     "grade": false,
     "grade_id": "Task3_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "df1.iloc[:2,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "793b7576be66d69571b3a716b5fe226b",
     "grade": true,
     "grade_id": "Task3_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST & AUTOGRADE CELL\n",
    "@run_unittest\n",
    "class test_task_3(unittest.TestCase):\n",
    "    def test_00(self): aeq(df1.T['abagael'][:5], [1,.074,.663,.229,.643], decimal=3)\n",
    "    def test_01(self): aeq(df1.T['abagael'].sum(), 5.760784632526338, decimal=3)\n",
    "    def test_02(self): aeq(df1.T['abagail'].sum(), 3.7565809320658445, decimal=3)\n",
    "    def test_03(self): aeq(df1[0].sum(), -706.9891949769153, decimal=3)\n",
    "    def test_04(self): aeq(df1.query('Y==1').sum().sum(), 11999.755633788649, decimal=3)\n",
    "    def test_05(self): aeq(df1.sum().sum(), 10487.074652241812, decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "51c65bff0925ac9c71851d9c12475680",
     "grade": false,
     "grade_id": "Task4_read",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Task 4. Train and Validate Logistic Regression Classifier\n",
    " \n",
    "Use [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split Pandas DataFrame `df1` (without `Y` column) and Pandas series `Y` (a column from `df1` DataFrame) into objects:\n",
    " \n",
    "1. `tX` = a Pandas DataFrame with a columns 0-49, a training input feature\n",
    "1. `vX` = a Pandas DataFrame with a column 0-49, a validation input feature\n",
    "1. `tY` = a Pandas series, a column `Y`, containing training labels for the corresponding rows in `tX`\n",
    "1. `vY` = a Pandas series, a column `Y`, containing validation labels for the corresponding rows in `vX`\n",
    " \n",
    "Then proceed with model fitting and evaluation:\n",
    " \n",
    "1. Create a [`LogisticRegression()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) object, `lr`. \n",
    "1. Fit it to `tX,tY` using the [`lr.fit()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit) method. \n",
    "1. Compute the model accuracy with [`lr.score()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score) method and appropriate input/output arguments.\n",
    " \n",
    "If done correctly, your model should score about 81% validation accuracy and 81% train accuracy.\n",
    " \n",
    "To ensure reproducibility of your model results, leave all function arguments at their default values, except:\n",
    " \n",
    "1. Set `random_state` to 0 for both functions.\n",
    "1. Use `test_size` of 0.2 for the split. That is, 20% is allocated to validation sets, `vX,vY`, and 80% is allocated to train sets, `tX,tY`.\n",
    " \n",
    "Hint: See previous course videos and Jupyter notebooks for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "235cf3e94bca77ebdb9580e985df300c",
     "grade": false,
     "grade_id": "Task4_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "pd.DataFrame(lr.get_params(deep=True).items()).set_index(0).T  # print model hyperparameters as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e47269a3db57ddca213a6af8945393e5",
     "grade": true,
     "grade_id": "Task4_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST & AUTOGRADE CELL\n",
    "@run_unittest\n",
    "class test_task_4(unittest.TestCase):\n",
    "    def test_00(self): eq(type(tX), pd.DataFrame)\n",
    "    def test_01(self): eq(type(vX), pd.DataFrame)\n",
    "    def test_02(self): eq(type(tY), pd.Series)\n",
    "    def test_03(self): eq(type(vY), pd.Series)\n",
    "    def test_04(self): eq(tX.shape, (6063, 50))\n",
    "    def test_05(self): eq(vX.shape, (1516, 50))\n",
    "    def test_06(self): eq(tY.shape, (6063, ))\n",
    "    def test_07(self): eq(vY.shape, (1516, ))\n",
    "    def test_08(self): eq(tX.index[:5].tolist(), ['rahul', 'elisabet', 'giuseppe', 'selie', 'jean-pierre']) # check the ordering of rows\n",
    "    def test_09(self): aeq((lr.score(vX, vY), lr.score(tX, tY)), (0.837730870712401, 0.838693715982187), decimal=3)\n",
    "    def test_10(self): eq(lr.get_params()['random_state'], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe8fc27afeb5b01490be1836803e08c4",
     "grade": false,
     "grade_id": "Task5_read",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Task 5. Build Predictions and AUC\n",
    " \n",
    "The accuracy computed above is overstated because the two classes are not balanced (i.e., not equal in their counts of observations). A more reliable metric in such case is Area Under the ROC Curve ([AUC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)), which you examined earlier in the video and Jupyter Notebook (JN). In the cell below compute `pY`, which is a NumPy array of probabilities of class=1 (i.e., name is that of a female) for validation observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58c4121f8a123b3f555a08c7f7375b14",
     "grade": false,
     "grade_id": "Task5_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "pY, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "233e20d2cda1d84a86cdd6e3143114a6",
     "grade": true,
     "grade_id": "Task5_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST & AUTOGRADE CELL\n",
    "@run_unittest\n",
    "class test_task_5(unittest.TestCase):\n",
    "    def test_00(self): eq(type(pY), np.ndarray)\n",
    "    def test_01(self): eq(pY.shape, (1516,))\n",
    "    def test_02(self): eq(tX.index[:5].tolist(), ['rahul', 'elisabet', 'giuseppe', 'selie', 'jean-pierre']) # check the ordering of rows\n",
    "    def test_03(self): aeq(pY[:5], [0.04161141, 0.53286882, 0.97318801, 0.95680585, 0.74057672], decimal=3)\n",
    "    def test_04(self): aeq(pY.sum(), 937.4494763770035, decimal=3)\n",
    "    def test_05(self): aeq(AUC, 0.8720775675213581, decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted probabilities (and the resulting predicted labels) can then be compared to the corresponding true labels to compute the confusion matrix and various aggregate measures of quality, which can help in model improvement."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
