# Class 5: Clustering Documents With Unsupervised Machine Learning

## Section 1: Use Metrics To Determine Text Similarity
| Lesson          |         Discription                                | Colab link    |
|-------------------|----------------------------------------------|------|
| **Module Intro**   | - become familiar with two major similarity measures: lexical and semantic similarity practice evaluating the similarity between words by computing the distance virus identification and spell-check problems using the Hamming and Levenshtein distance metrics    Measuring the similarity between words in this module will prepare you for the document categorization     |  |
|**Vid: pare Texts Using Similarity Metrics**|lexical similarity, which is based on syntax, structure, and content, is commonly used for autocomplete and spell check applications. Semantic similarity, by contrast, uses context to evaluate the similarity in meaning between words or documents.|
|**Compare Texts Using Similarity Metrics**|1 how to calculate **Jaccard similarity** and use a correlation function to compare two words. 2 practice applying Jaccard similarity to both characters and words.|
|**Code: Practice Comparing Texts Using Similarity Metrics**|Binary comparison 2 Jaccard similarity 3. Correlation 4 using ord() to convert to ASCII |[![Open in Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/matsunagateitoku/stdp-class/blob/main/4.1.1.Practice_Comparing_Texts.ipynb) |
|**Find Mismatches With Hamming Distance**|**Hamming distance** is another way to measure the distance between words, when working with two strings of equal length number of substitutions needed to make two strings equal|
|**Practice Finding Mismatches With Hamming Distance**|Hamming Distance=opposite of similarity. sequences of equal length, counts positions that corresponding characters are differen | [![Open in Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/matsunagateitoku/stdp-class/blob/main/Practice_Finding_Mismatches.ipynb)|
|**Similarity Measures**||
|**Comparing Sequences With Levenshtein Distance**||
|**Compute Levenshtein Distance**||
|**Practice Comparing Sequences With Levenshtein Distance**||[![Open in Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/matsunagateitoku/stdp-class/blob/main/Practice_Comparing_Sequences.ipynb)|
|**Use Levenshtein Distance To Autocorrect Text**||
|**Practice Using Levenshtein Distance To Autocorrect Text**||
|**Review: Similarity and Distances Metrics**||
|**Course Project, Part One — Using Metrics To Determine Text Similarity**|1. computes Jaccard similarity 2. ompute Jaccard similarity scores for SsQry set and each presidential speech in NLTK 3. Hamming distance;; Marker(), which takes two same-length strings, query sQry and target sTgt, and computes returns a "marked" string sTgt where the characters matching to corresponding characters in sQry are replaced with _. 4 ankHD(), which takes two strings: query sQry and target sTgt, of varying lengths. Then, for each substring in sTgt with length equal to len(sQry), compute the Hamming distance and the corresponding marked string.





|
|**Module Wrap-up: Use Metrics To Determine Text Similarity**||

## Section 2: Use Metrics To Determine Text Similarity
| Lesson          |         Discription                                | Colab link    |
|-------------------|----------------------------------------------|------|
|**Module Introduction: Perform Hierarchical Clustering on Sentence Embeddings To Group Similar Texts**||
|**Embed Sentences Into Vectors**||
|**Practice Embedding Sentences Into Vectors**||
|**Compute Similarity of Sentence Embeddings To Find Similar Movies**||
|**Practice Computing Similarity of Sentence Embeddings To Find Similar Movies**||
|**Methods for Clustering**||
|**Hierarchical Clustering of Movies Based on Their Descriptions**||
|**Practice Hierarchical Clustering of Movies Based on Their Descriptions**||
|**The Anatomy of a Dendrogram**||
|**Interpreting a Dendrogram**||
|**Build Dendrograms Using Different Linkages**||
|**Practice Building Dendrograms Using Different Linkages**||
|**Identify Linkages in Dendrograms**||
|**Measure Clustering Performance**||
|**Practice Measuring Clustering Performance**||
|**Course Project, Part Two — Performing Hierarchical Clustering on Sentence Embeddings To Group Similar Texts**||
|**Module Wrap-up: Perform Hierarchical Clustering on Sentence Embeddings To Group Similar Texts**||

## Section 3: Perform K-Means Clustering on Sentence Embeddings To Group Similar Texts
| Lesson          |         Discription                                | Colab link    |
|-------------------|----------------------------------------------|------|
|**Module Introduction: Perform K-Means Clustering on Sentence Embeddings To Group Similar Texts**||
|**Calculate Centroids and Medoids To Find a Representative Data Point**||
|**Practice Calculating Centroids and Medoids To Find a Representative Data Point**||
|**Compute the Medoid To Find a Representative Movie**||
|**Practice Computing the Medoid To Find a Representative Movie**||
|**Clustering Movies With K-Means and Evaluating Performance**||
|**Practice Clustering Movies With K-Means and Evaluating Performance**||
|**Hierarchical and K-Means Clustering**||
|**Course Project, Part Three — Perform K-Means Clustering on Sentence Embeddings To Group Similar Texts**||
|**Module Wrap-up: Perform K-Means Clustering on Sentence Embeddings To Group Similar Texts**||
|**Glossary**||
|**Course Transcript**||


