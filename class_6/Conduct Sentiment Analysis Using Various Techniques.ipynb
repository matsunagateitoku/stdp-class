{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part Three of the Course Project**\n",
    "In this part of the course project, you will automatically expand the VADER's lexicon using TextBlob's sentiment analyzer on words missing from the VADER's vocabulary. Then you'll measure the f1 score with and without this expansion.<hr style=\"border-top: 2px solid #606366; background: transparent;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**\n",
    " \n",
    "Reset the Python environment to clear it of any previously loaded variables, functions, or libraries. Then, import the libraries and corpora needed for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from IPython.core.interactiveshell import InteractiveShell as IS\n",
    "IS.ast_node_interactivity = 'all'\n",
    "import numpy as np, pandas as pd, nltk, unittest, numpy.testing as npt\n",
    "from textblob import TextBlob  # version 0.17.1\n",
    "from sklearn.metrics import classification_report as rpt\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "_ = nltk.download(['vader_lexicon', 'movie_reviews', 'punkt', 'sentence_polarity', 'omw-1.4'], quiet=True)\n",
    "from nltk.corpus import movie_reviews, sentence_polarity, wordnet as wn\n",
    "from colorunittest import run_unittest\n",
    "eq, aeq = npt.assert_equal, npt.assert_almost_equal\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "pd.set_option('max_colwidth', 100, 'max_rows', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting size of VADER''s lexicon:', len(sia.lexicon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "Complete `ApplySIA()`, which takes lists of positive and negative reviews and returns a dataframe with these reviews in original order and relevant statistics from VADER's sentiment intensity analyzer. This includes negative (`neg`), neutral (`neu`), positive (`pos`), `compound` scores, and original polarity `vY`. The field `pY` is 1 for positive compound score, -1 for negative compound score and zero otherwise.\n",
    "\n",
    "For example, `ApplySIA(['good'], ['bad'])` returns\n",
    "\n",
    "|neg|neu|pos|compound|vY|pY|review|\n",
    "|-|-|-|-|-|-|-|\n",
    "|0|0.0|1.0|0.4404|1|1|good|\n",
    "|1|0.0|0.0|-0.5423|-1|-1|bad|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27bfcb598b49a5f641b7152575fe71e1",
     "grade": false,
     "grade_id": "ApplySIA_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def ApplySIA(LsPos=[''], LsNeg=[''], sia=sia) -> pd.DataFrame:\n",
    "    ''' Add positive reviews LsPos and negative reviews LsNeg to a dataframe\n",
    "        with their polarity_scores from SentimentIntensityAnalyzer().\n",
    "        Then add a test polarity vY as 1 and a predicted polarity pY as thresholded compound score.\n",
    "        Then add negative reviews with vY=-1 and other statistics from SentimentIntensityAnalyzer()\n",
    "    Input:\n",
    "        LsPos, LsNeg: lists with positive and negative review texts, respectively\n",
    "    Returns: dataframe     '''\n",
    "    df = pd.DataFrame([], columns=['neg neu pos compound vY pY review'.split()]) # desired output structure\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return df\n",
    "\n",
    "df1 = ApplySIA([' '.join(sSent) for sSent in sentence_polarity.sents('rt-polarity.pos')], \n",
    "               [' '.join(sSent) for sSent in sentence_polarity.sents('rt-polarity.neg')])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e93fe7ed72d3ae3dc08f9493eb85db5",
     "grade": true,
     "grade_id": "ApplySIA_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "df0 = ApplySIA(['good'], ['bad'])\n",
    "\n",
    "@run_unittest\n",
    "class Test_ApplySIA(unittest.TestCase):\n",
    "    def test00(self): eq(type(df0), pd.DataFrame)\n",
    "    def test01(self): eq(df0.shape, (2,7))\n",
    "    def test02(self): eq(list(df0.columns), ['neg', 'neu', 'pos', 'compound', 'vY', 'pY', 'review'])\n",
    "    def test03(self): eq(df0.values.tolist(), [[0,0,1,.4404,1,1,'good'], [1,0,0,-.5423,-1,-1,'bad']])\n",
    "    def test04(self): eq(df1.shape, (10662, 7))\n",
    "    def test05(self): eq(df1.iloc[0,:6].tolist(), [0.0, 0.918, 0.082, 0.3612, 1, 1])\n",
    "    def test06(self): eq(df1.iloc[-1].tolist(), [0,1,0,0,-1,1,\"enigma is well-made , but it's just too dry and too placid .\"])\n",
    "    def test07(self): aeq(df1.compound[:5].tolist(), [0.3612, 0.8069, 0.2617, 0.8271, 0.6592], 4) # checking row order\n",
    "    def test08(self): aeq(df1.mean().tolist(), [0.0913, 0.7449, 0.1639, 0.1633, 0.0, 0.4219], 4)  # checking all columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "Complete `OOV()` UDF, which removes all words from `Docs` iterable which are either one character long or contain non-alpha characters or are present in `Vocab` iterable (when lower-cased). \n",
    "\n",
    "This function collects the words out of VADER's lexicon, so that we could score these words and add them to the lexicon.\n",
    "\n",
    "For example, `OOV(['Good Goods . ', 'a lucky7'])` returns `{'goods'}` because the other words in `['good', 'goods', '.', 'a', 'lucky7']` are either too short or non-alpha or already have a valency score in `sia.lexicon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb3e6908a59055dd4eb51bbadc20bf1f",
     "grade": false,
     "grade_id": "OOV_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def OOV(Docs=df1.review, Vocab=sia.lexicon) -> set(''):\n",
    "    ''' Out of Vocab (OOV) UDF returns a subset of words in Docs which are not in Vocab.\n",
    "        Docs are joined by space, lower-cased, and split on whitespace using split() of a string.\n",
    "    Inputs:\n",
    "        Docs: an iterable of string elements (list, Series, tuple, set, dict.keys, etc.)\n",
    "        Vocab: iterable with string keys.\n",
    "    Returns: set of strings of alpha words (over 1 char), which are not in Lexicon     '''\n",
    "    SsNewWords = set('')  # desired output format\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return SsNewWords\n",
    "\n",
    "SsOOV = OOV()  # unscored words\n",
    "OOV(['Good Goods . ', 'a lucky7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe36a6bb1bfcfb5c60ca59f9b46ac250",
     "grade": true,
     "grade_id": "OOV_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "s0 = OOV(['Good Goods . ', 'a lucky7'])\n",
    "\n",
    "@run_unittest\n",
    "class Test_OOV(unittest.TestCase):\n",
    "    def test00(self): eq(type(s0), set)\n",
    "    def test01(self): eq(len(s0), 1)\n",
    "    def test02(self): eq(s0, {'goods'})\n",
    "    def test03(self): eq(sorted(SsOOV)[:5], ['aaa', 'aaliyah', 'aan', 'abandone', 'abandono'])\n",
    "    def test04(self): eq(OOV([df1.review[6]]), {'and', 'combination', 'education', 'of', 'offers', 'rare', 'that'}) \n",
    "    def test05(self): eq(len(SsOOV), 14868)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "\n",
    "Complete the `Expand()` UDF, which extends the given set of words with their other morphological forms using WordNet's `morphy()` method. All original and morphed words will later be assigned valency (by TextBlob model) and added to VADER's lexicon with their new scores. Since given a word, one doesn't know which POS it uses in a sentence, you assume that either POS can be used with an equal chance and add all possible simplified POS forms of this word back to the set.\n",
    "\n",
    "The example below uses `wn.morphy()` to standardize different morphologies of `run` to their base form assuming different POS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.morphy('runs', wn.NOUN), wn.morphy('runs', wn.ADJ), wn.morphy('runs', wn.VERB), \\\n",
    "wn.morphy('running', wn.NOUN), wn.morphy('running', wn.ADJ), wn.morphy('running', wn.VERB), \\\n",
    "wn.morphy('ran', wn.NOUN), wn.morphy('ran', wn.ADJ), wn.morphy('ran', wn.VERB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, `Expand({'run','runs','ran','running'})` should return (ordered)\n",
    "\n",
    "    ['ran', 'run', 'running', 'runs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c71c998b0a5b22a05a8ac600372867f0",
     "grade": false,
     "grade_id": "Expand_anser",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def Expand(SsWords={''}) -> list(''):\n",
    "    ''' Expand() takes a set of words and adds morphed nouns, adjectives and verbs of these words\n",
    "        using wn.morphy() function, which takes a word and a POS (wn.NOUN, wn.ADJ, or wn.VERB)\n",
    "    Inputs:   SsWords: a set of word strings\n",
    "    Returns:  an alphabetically ordered list of original and added words     '''\n",
    "    SsWordsNew = set('')\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return SsWordsNew\n",
    "\n",
    "LsOOV2 = Expand(SsOOV)  # expanded list of words\n",
    "print(LsOOV2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85e6d4b5b05a7165e5ae2cbe36626a5c",
     "grade": true,
     "grade_id": "Expand_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "e0 = Expand({'run','runs','ran','running'})\n",
    "\n",
    "@run_unittest\n",
    "class Test_Expand(unittest.TestCase):\n",
    "    def test00(self): eq(type(e0), list)\n",
    "    def test01(self): eq(len(e0), 4)\n",
    "    def test02(self): eq(e0, ['ran', 'run', 'running', 'runs'])\n",
    "    def test03(self): eq(len(LsOOV2), 16224)\n",
    "    def test04(self): eq(LsOOV2[:5], ['aaa', 'aaliyah', 'aan', 'abandone', 'abandono']) \n",
    "    def test05(self): eq(LsOOV2[-5:], ['ótimo', 'último', 'últimos', 'única', 'único'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "\n",
    "Complete `GetScores()` UDF so that it takes a list of words and keeps those for which it can retrieve a valence score using TextBlob's `polarity` attribute. \n",
    "\n",
    "For example `GetScores(['smart','cry','liked','sweet','sour'])` returns \n",
    "\n",
    "    [('smart', 0.8571428571428571), ('liked', 2.4), ('sweet', 1.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52978a850121f2671adf5c0fb2272c6b",
     "grade": false,
     "grade_id": "GetScores_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def GetScores(LsWords=LsOOV2) -> [(str,int)]:\n",
    "    ''' For every word in LsWords, find its polarity score using TextBlob(..).polarity. \n",
    "        Then add the word and 4*polarity tuple to the list LsWS.\n",
    "        Polarity scaling ensures that these are in the range [-4,4], \n",
    "        which coincides with VADER's valence score.\n",
    "        Keep the word ordering the same and drop words with zero polarity.\n",
    "    Input:    list of string words\n",
    "    Return:   a list of tuples in the form (word, valence score)      ''' \n",
    "    LTsWS = [('',0)]    # desired output format\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return LTsWS\n",
    "\n",
    "%time LTsWS = GetScores()\n",
    "print(LTsWS[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3a8e1a59a2b75e5c4f5fb5f0b51e031",
     "grade": true,
     "grade_id": "Test_Expand_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "g0 = GetScores(['smart','cry','liked','sweet','sour'])\n",
    "\n",
    "@run_unittest\n",
    "class Test_Expand(unittest.TestCase):\n",
    "    def test00(self): eq(type(g0), list)\n",
    "    def test01(self): eq(len(g0), 4)\n",
    "    def test02(self): eq(g0, [('smart', 0.8571428571428571), ('liked', 2.4), ('sweet', 1.4),  ('sour', -0.6000000000000001)])\n",
    "    def test03(self): eq(len(LTsWS), 780)\n",
    "    def test04(self): eq(LTsWS[:4], [('able', 2.0), ('ably', 2.0), ('abridged', 0.4), ('abrupt', -0.5)]) \n",
    "    def test05(self): eq(LTsWS[-4:], [('witty', 2.0), ('workmanlike', 2.0), ('yarn', -0.4), ('young', 0.4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reapply Expanded VADER\n",
    "\n",
    "Next, the VADER's lexicon is expanded with the new words in `LTsWS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [sia.lexicon.update({w: s}) for w,s in LTsWS]\n",
    "print('New size of VADER''s lexicon:', len(sia.lexicon))  # now VADER should have 7877 words in its lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then `df2` dataframe is computed using the improved VADER's sentiment analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df2 = pd.DataFrame([sia.polarity_scores(s) for s in df1.review])\n",
    "df2['review'] = df1.review\n",
    "df2['vY'] = df1.vY\n",
    "df2['pY'] = df2.compound.apply(lambda c: -1 if c < 0 else 1 if c >= 0 else 0)   # predicted polarity (based on threshold)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the Performance\n",
    "\n",
    "Next performance metrics are recomputed for the SIA model using the original and expanded vocabulary. While Precision and Recall improved more than they deteriorated in the new model, the f1 score has dropped by more than it improved. I.e. it dropped by 0.03 from 0.51 to 0.48 and improved by 0.01 from 0.68 to 0.69. \n",
    "\n",
    "An important takeaway is that no hypothesis of improvement guarantees the improvement in the model performance. Each idea needs to be tested on the given data. In general, brainstorming many ideas is great as it allows one to choose those that appear most profitable and least costly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rpt(y_true=df1.vY, y_pred=df1.pY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rpt(y_true=df2.vY, y_pred=df2.pY))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
