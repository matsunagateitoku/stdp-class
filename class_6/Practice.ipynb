{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**\n",
    " \n",
    "Reset the Python environment to clear it of any previously loaded variables, functions, or libraries. Then, import the libraries needed to complete the code Professor Melnikov presented in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from IPython.core.interactiveshell import InteractiveShell as IS\n",
    "IS.ast_node_interactivity = \"all\"    # allows multiple outputs from a cell\n",
    "import numpy as np, nltk, pandas as pd\n",
    "from nltk.corpus import wordnet as wn\n",
    "_ = nltk.download(['punkt', 'averaged_perceptron_tagger', 'wordnet', 'stopwords'], quiet=True)\n",
    "SsStopwords = set(nltk.corpus.stopwords.words())            # set of strings of stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n",
    "\n",
    "# **Review**\n",
    "\n",
    "Review the code Professor Melnikov used to measure a similarity between a pair of sentences.\n",
    "\n",
    "To compare two sentences using a WordNet ontological database, you first need to tokenize each sentence and assign POS tags, which are used in identifying the most relevant synset. Not all tokens can be translated to synsets, so some preprocessing can be helpful to change plural nouns to singular or to change other verb forms to the base form. Next, for each sense of a word in one document you could try locating the most relevant sense of a word in the second document. Then compute the path similarity between these and average all path similarities at the end to derive the final similarity between two texts. This process is overly simplified, but it opens up opportunities for improvements.\n",
    "\n",
    "Recall that WordNet can help with some preprocessing as it has built in functions to lemmatize words as shown below. Below, use the functions `morphy` and `lemmatize` to look up other forms of the given strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.morphy('cats', pos='n')\n",
    "nltk.WordNetLemmatizer().lemmatize('cats', pos='n')\n",
    "nltk.WordNetLemmatizer().lemmatize('walking', pos='v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UDF `SplitNTag()` tokenizes an argument `sDoc` and retrieves POS tags for the resulting tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DssTags = dict(N='n', J='a', R='r', V='v') # convert NLTK POS to WordNet POS: noun, adjective, adverb, verb\n",
    "\n",
    "def SplitNTag(sDoc='I ate a red bean.', sDefaultTag='n', SsStop=SsStopwords, nMinLen=2):\n",
    "    ''' Tokenize & clean a document. Return list of tuples (word, WordNet tag).\n",
    "    sDoc:        a string sentence or document\n",
    "    sDefaultTag: default tag to use if NLTK tag is not a key in DssTags\n",
    "    SsStop:      set of stopword strings to discard\n",
    "    nMinLen:     min length of words to keep  '''\n",
    "    LTssTokTag = nltk.pos_tag(nltk.word_tokenize(sDoc)) # word and NLTK tag\n",
    "    return [(w, DssTags.get(t[:1], sDefaultTag)) for w, t in LTssTokTag if (w not in SsStopwords) and len(w)>nMinLen]\n",
    "SplitNTag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UDF `Doc2Syn()` retrieves the first synset (if available) for each token+POS in a document. It uses a strong assumption that the first synset is the most likely, which is sometimes not the case. If a text’s context is used (for example via a pre-trained language model such as SBERT) then it may be possible to draw a more relevant synset, possibly at a higher computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc2Syn = lambda s='I rode a bike': [wn.synsets(i, z)[0] for i, z in SplitNTag(s) if wn.synsets(i, z)] # list of synsets in document\n",
    "\n",
    "print([s.name() for s in Doc2Syn()])\n",
    "print([s for s in Doc2Syn('brand new laptop')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UDF `SynSim()` is a wrapper for `wn.path_similarity()`, which returns a zero if no path is found between two synsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SynSim(ss1=wn.synset('cat.n.01'), ss2=wn.synset('cat.v.01')):\n",
    "    ''' Return similarity score between two synsets '''\n",
    "    nSim = wn.path_similarity(ss1, ss2) # path similarity between 2 synset objects\n",
    "    return nSim if nSim else 0          # replace None with 0, which will be ignored by max()\n",
    "\n",
    "SynSim(ss1=wn.synset('cat.n.01'), ss2=wn.synset('cat.n.02'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UDF `SynsSim()` takes two lists of synsets and computes average similarity for best-matched pairs from the two lists. If `debug` is turned on, it prints the intermediate similarities for the pairs.\n",
    "\n",
    "Note that the current UDF computes an asymmetric similarity, that is the similarity between LS1 and LS2 may differ from the similarity between LS2 and LS1. This is because the function finds the best-matched tokens in LS2 for each token in LS1.\n",
    "\n",
    "While this function can be improved, it serves our purpose for demonstrating the computation of the rough similarity between two texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max0 = lambda X: max(X, default=0)   # wrapper for max() with default for None's set to 0\n",
    "\n",
    "def SynsSim(LS1=wn.synsets('cat'), LS2=wn.synsets('dog'), debug=False):\n",
    "    '''Return average similarity for best-matched pairs of synsets from two lists of synsets.\n",
    "     debug: if true, prints best-matched synset names'''\n",
    "    if debug: print('-'*20, f'\\n>LS1: {[ss.name() for ss in LS1]}', f'\\n>LS2: {[ss.name() for ss in LS2]}')\n",
    "    if not LS1 or not LS2:\n",
    "        print('WARNING: At least one synset is empty')\n",
    "        return 0\n",
    "\n",
    "    # Ensure similarity is the first in a tuple\n",
    "    LnSims = [max0([(SynSim(ss1, ss2), ss1.name(), ss2.name()) for ss2 in LS2]) for ss1 in LS1] # double loop\n",
    "    nAvgSim = sum(list(zip(*LnSims))[0])/len(LnSims) if len(LnSims) > 0 else 0  # average similarity\n",
    "    if debug: print('Best-matched synset pairs:',', '.join([f'{s}|{s2}|{n:.2f}' for n,s,s2 in LnSims]), f\"\\nAvg sim: {nAvgSim:.2f}\")\n",
    "    else: return nAvgSim\n",
    "\n",
    "LSyn1, LSyn2 = wn.synsets('lion'), wn.synsets('tiger')\n",
    "SynsSim(LSyn1, LSyn2, debug=True)\n",
    "SynsSim(LSyn2, LSyn1, debug=True)\n",
    "SynsSim(Doc2Syn('it rains outside'), Doc2Syn('rain is outside'), debug=True)\n",
    "SynsSim(Doc2Syn('it rains outside'), Doc2Syn('it pours outdoors'), debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if the `debug` is switched off, you can compute the similarities between sentences. In the first pair `rain` is a *verb* in the first sentence and a *noun* in the second sentence. This results in poorer extraction of a synset, yielding a relatively low similarity. The last two sentences are in line with the expectation that *'raining cats and dogs'* is still related to rain, while the *'brand new laptop'* is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DocSim(sDoc1='it rains outside', sDoc2='rain is outside'):\n",
    "    LTs1, LTs2 = Doc2Syn(sDoc1), Doc2Syn(sDoc2)\n",
    "    return (SynsSim(LTs1, LTs2) + SynsSim(LTs2, LTs1)) / 2\n",
    "\n",
    "print(DocSim('it rains outside', 'rain is outside'))               # rain is a verb and a noun\n",
    "print(DocSim('it rains outside', 'it is a pouring rain outdoors')) # rain is a verb and a noun\n",
    "print(DocSim('it rains outside', 'raining cats and dogs'))         # rain is a verb in both sentences\n",
    "print(DocSim('it rains outside', 'brand new laptop'))              # there is no `rain` word in the 2nd sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n",
    "\n",
    "# **Optional Practice**\n",
    "\n",
    "Now you will practice computing similarities between documents. Consider this list of quotes about language.\n",
    "\n",
    "As you work through these tasks, check your answers by running your code in the *#check solution here* cell, to see if you’ve gotten the correct result. If you get stuck on a task, click the See **solution** drop-down to view the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LsQuote=[\"A different language is a different vision of life.\", # Federico Fellini\n",
    "  \"The limits of my language mean the limits of my world.\",     # Ludwig Wittgenstein\n",
    "  \"One language sets you in a corridor for life. Two languages open every door along the way.\",  # Frank Smith\n",
    "  \"He who knows no foreign languages knows nothing of his own.\",  # Johann Wolfgang von Goethe\n",
    "  \"You can never understand one language until you understand at least two.\",  # Geoffrey Willans\n",
    "  \"To have another language is to possess a second soul.\",      # Charlemagne\n",
    "  \"Change your language and you change your thoughts.\",         # Karl Albrecht\n",
    "  \"Knowledge of languages is the doorway to wisdom.\",           # Roger Bacon\n",
    "  \"Language is the blood of the soul into which thoughts run and out of which they grow.\",  # Oliver Wendell Holmes\n",
    "  \"Learn a new language and get a new soul.\",                   # Czech Proverb\n",
    "  \"A special kind of beauty exists which is born in language, of language, and for language.\",  # Gaston Bachelard\n",
    "  \"Learning is a treasure that will follow its owner everywhere.\",  # Chinese Proverb\n",
    "  \"One should not aim at being possible to understand but at being impossible to misunderstand.\",  # Marcus Fabius Quintilian\n",
    "  \"A mistake is to commit a misunderstanding.\",                  # Bob Dylan\n",
    "  \"Language is to the mind more than light is to the eye.\"]     # William Gibson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Compute a similarity score for each quote in `LsQuote` in relation to the search quote `'languages around the World'`.\n",
    "\n",
    "<b>Hint:</b> Use <code>DocSim()</code> to compute similarity for each quote. You can do this in a loop or list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details><summary><font color=#B31B1B>▶ </font>See <b>solution</b>.</summary>\n",
    "<pre class=\"ec\">\n",
    "sQuery = 'languages around the World'\n",
    "sorted([(round(DocSim(sQuery, q), 3), q) for q in LsQuote], reverse=True)\n",
    "</pre>\n",
    "</details> \n",
    "</font>\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
