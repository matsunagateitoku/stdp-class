{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part One of the Course Project**\n",
    "In this part of the course project, you will manipulate NLTK's WordNet taxonomy.\n",
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**\n",
    " \n",
    "Reset the Python environment to clear it of any previously loaded variables, functions, or libraries. Then, import the libraries and corpora needed for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from IPython.core.interactiveshell import InteractiveShell as IS\n",
    "IS.ast_node_interactivity = \"all\"    # allows multiple outputs from a cell\n",
    "import numpy as np, nltk, pandas as pd, numpy.testing as npt, unittest\n",
    "from nltk.corpus import wordnet as wn\n",
    "from colorunittest import run_unittest\n",
    "ae, aae = npt.assert_equal, npt.assert_almost_equal\n",
    "\n",
    "_ = nltk.download(['punkt', 'averaged_perceptron_tagger', 'wordnet', 'omw-1.4'], quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Complete UDF `Lemmas()`, which takes `sLemma` lemma word, finds all related synsets `SS` and returns the set of lemma names from all synsets in `SS`.\n",
    "\n",
    "*Example:* the lemma `'tiger'` leads to synsets:\n",
    "\n",
    "1. `Synset('tiger.n.01')` with the lemma names `['tiger']`\n",
    "1. `Synset('tiger.n.02')` with the lemma names `['tiger', 'Panthera_tigris']`. \n",
    "\n",
    "The concatenated list `['tiger', 'tiger', 'Panthera_tigris']` is converted to the output set `{'tiger', 'Panthera_tigris'}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e469410a88720f377e0f92e679b1876",
     "grade": false,
     "grade_id": "Lemma_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CELL\n",
    "def Lemmas(sLemma='tiger') -> set():\n",
    "    '''Returns a set of all lemma names from all synsets of sLemma.  '''\n",
    "    SsLemmas = set()  # set of lemmas\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return SsLemmas\n",
    "\n",
    "Lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bee610e2e7c1fe2685cf11584ec62afd",
     "grade": true,
     "grade_id": "Lemma_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "@run_unittest\n",
    "class Test_Lemmas(unittest.TestCase):\n",
    "    def test00(self): ae(type(Lemmas()), set)\n",
    "    def test01(self): ae(Lemmas('tiger'), {'Panthera_tigris', 'tiger'})\n",
    "    def test02(self): ae(Lemmas('teacher'), {'instructor', 'teacher'})\n",
    "    def test03(self): ae(Lemmas('Cornell'), {'Cornell', 'Ezra_Cornell', 'Katherine_Cornell'})\n",
    "    def test04(self): ae(len(Lemmas('cat')), 38)\n",
    "    def test05(self): ae(len(Lemmas('Dogs')), 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Complete UDF `Hypernyms()`, which takes `sLemma` lemma word, finds all related synsets `SS` and returns the set of hypernym's lemma names from all synsets in `SS`.\n",
    "\n",
    "*Example:* the lemma `'tiger'` leads to synsets:\n",
    "\n",
    "1. `Synset('tiger.n.01')` with the hypernym synsets:\n",
    "    1. `Synset('person.n.01')` with lemmas `[['person', 'individual', 'someone', 'somebody', 'mortal', 'soul']]`\n",
    "1. `Synset('tiger.n.02')` with the hypernym synsets:\n",
    "    1. `Synset('big_cat.n.01')` with hypernym synset lemmas `[['big_cat', 'cat']]`. \n",
    "\n",
    "The flattened concatenated list `['person', 'individual', 'someone', 'somebody', 'mortal', 'soul', 'big_cat', 'cat']` is returned as a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf6d7599e4d91519ffb8c52da32178af",
     "grade": false,
     "grade_id": "HypLemmas_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CELL\n",
    "def HypLemmas(sLemma='tiger') -> set():\n",
    "    '''Returns a set of all lemma names from all the hypernyms of all the synsets of sLemma. '''\n",
    "    SsLemmas = set()  # set of lemmas\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return SsLemmas\n",
    "\n",
    "print(HypLemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f51cc1e54d8f063241d0e4a42a2be380",
     "grade": true,
     "grade_id": "HypLemmas_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "@run_unittest\n",
    "class Test_HypLemmas(unittest.TestCase):\n",
    "    def test00(self): ae(type(HypLemmas()), set)\n",
    "    def test01(self): ae(HypLemmas('tiger'), {'big_cat','cat','individual','mortal','person','somebody','someone','soul'})\n",
    "    def test02(self): ae(HypLemmas('teacher'), {'abstract','abstraction','educator','pedagog','pedagogue'})\n",
    "    def test03(self): ae(HypLemmas('Cornell'), set())\n",
    "    def test04(self): ae(len(HypLemmas('cat')), 30)\n",
    "    def test05(self): ae(len(HypLemmas('Dogs')), 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Complete UDF `Sim()`, which takes two lemmas and for each combination of their synsets computes a path similarity score. If `ReturnBest` is selected, then only the topmost similarity pairs are returned (which can be more than one). `Sim('teacher', 'tiger')` return the following dataframe (ordered by columns `ss1`, `ss2`):\n",
    "\n",
    "\n",
    "|.|ss1|ss2|sim|\n",
    "|-|-|-|-|\n",
    "|0|teacher.n.01|tiger.n.01|0.166667|\n",
    "|1|teacher.n.01|tiger.n.02|0.066667|\n",
    "|2|teacher.n.02|tiger.n.01|0.076923|\n",
    "|3|teacher.n.02|tiger.n.02|0.043478|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c07d1495b49bf5a4ed8d8556403ada43",
     "grade": false,
     "grade_id": "Sim_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CELL\n",
    "def Sim(sLemma1='teacher', sLemma2='tiger', ReturnBest=False) -> pd.DataFrame():\n",
    "    '''Computes WordNet's path similarity between all possible pairs of synsets from\n",
    "        sLemma1 and sLemma2.\n",
    "    Inputs:\n",
    "        sLemma1, sLemma2: strings, lemmas\n",
    "        ReturnBest: Boolean, specifies whether rows with max similarity should be returned only\n",
    "    Returns: dataframe with columns ss1 & ss2 indicating names of the synsets relating \n",
    "        to sLemma1, sLemma2, respectively. Column sim contains the corresponding similarity score.\n",
    "        Rows are ordered by ss1, ss2.      '''\n",
    "    dfSim = pd.DataFrame([], columns=['ss1', 'ss2', 'sim']) # format of returned dataframe\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return dfSim\n",
    "\n",
    "Sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7296c4fc366444257246a1da9c33a99",
     "grade": true,
     "grade_id": "Sim_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "@run_unittest\n",
    "class Test_Sim(unittest.TestCase):\n",
    "    def test00(self): ae(type(Sim()), pd.DataFrame)\n",
    "    def test01(self): ae(Sim().shape, (4,3))\n",
    "    def test02(self): ae(list(Sim().columns), ['ss1','ss2','sim'])\n",
    "    def test03(self): ae(Sim('monday','autumn').values.tolist(), \n",
    "        [['monday.n.01', 'fall.n.01', 0.14285714285714285]])\n",
    "    def test04(self): ae(Sim('teacher','autumn').values.tolist(), \n",
    "        [['teacher.n.01', 'fall.n.01', 0.07142857142857142],\n",
    "         ['teacher.n.02', 'fall.n.01', 0.07692307692307693]])\n",
    "    def test05(self): ae(Sim('cat','dog').shape, (80, 3))\n",
    "    def test06(self): ae(Sim('fall','break').shape, (3300, 3))\n",
    "    def test07(self): ae(Sim('fall','break', True).values.tolist(), \n",
    "        [['decrease.v.01', 'break.v.56', 0.5], ['decrease.v.01', 'break.v.58', 0.5]])\n",
    "    def test08(self): ae(Sim('cat','dog').sim.mean().round(4), 0.0881)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
