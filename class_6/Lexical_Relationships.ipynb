{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**\n",
    " \n",
    "<font color='black'>Reset the Python environment to clear it of any previously loaded variables, functions, or libraries. Then, import the libraries needed to complete the code Professor Melnikov presented in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from IPython.core.interactiveshell import InteractiveShell as IS\n",
    "IS.ast_node_interactivity = \"all\"    # allows multiple outputs from a cell\n",
    "import numpy as np, nltk, pandas as pd\n",
    "from nltk.corpus import wordnet as wn\n",
    "_ = nltk.download(['punkt', 'averaged_perceptron_tagger', 'wordnet', 'stopwords'], quiet=True)\n",
    "SsStopwords = set(nltk.corpus.stopwords.words())            # set of strings of stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n",
    "\n",
    "# **Review**\n",
    "\n",
    "<font color='black'>Review the code Professor Melnikov used to measure relationships and compute similarities between senses.</font>\n",
    "\n",
    "\n",
    "## Similarities Between Nouns\n",
    "\n",
    "<font color='black'>Before computing pairwise similarities, you should evaluate the senses of the synsets. Below are the definitions of each synset that is used in later analysis. Several feline synsets are chosen on purpose to illustrate that similarities among these are stronger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TsWords = ('cat', 'lion', 'tiger', 'tree', 'ant', 'reagan', 'gates', 'red')\n",
    "LSyn = [wn.synsets(s, pos='n')[0] for s in TsWords]         # list of primary synsets\n",
    "_ = [print(s.name(),':\\t', s.definition()) for s in LSyn]   # print synset name and definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='black'>The next cell produces symmetric matrix modeling similarities between synset pairs, as well as each pair's **lowest common hypernym** ([LCH](https://www.nltk.org/howto/wordnet_lch.html#wordnet-lowest-common-hypernyms)). The LCH is the shared hypernym closest to each synset in a pair and is produced by a synset's method `lowest_common_hypernyms()`. \n",
    "\n",
    "A lower LCH indicates a greater similarity of senses among two synsets. In the example below, `cat` is more similar to `lion` than `tiger`, as indicated by a higher similarity (0.25 vs 0.09). `cat` and `lion` also share a lower LCH (`feline`) than `cat` and `tiger` (`organism`). Recall that hyponyms follow this path:\n",
    "\n",
    "      entity ... → ... organism ... → ... feline ... → ...\n",
    "\n",
    "Also note that `cat` has a similarity of one when compared with `cat`. In this case, the LCH is `cat` itself (the closest possible node) in this directed acyclic graph ([DAG](https://www.nltk.org/book/ch09.html#directed_acyclic_graphs_index_term)). On the contrary, color `red` has the lowest similarity with all other terms. It's LCH is `entity` (the root of the WordNet DAG).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCP = lambda ss, ss2: ss.lowest_common_hypernyms(ss2)[0].lemmas()[0].name() # name of first lemma in common parent synset\n",
    "Sim = lambda ss, ss2: f'{LCP(ss, ss2)}, {wn.path_similarity(ss,ss2):.2f}'   # parent synset+similarity for both synsets\n",
    "LLnSim = [[Sim(ss, ss2) for ss2 in LSyn] for ss in LSyn]                    # double loop; similarities for synset pairs\n",
    "pd.DataFrame(LLnSim, index=TsWords, columns=TsWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarities Between Different POS\n",
    "\n",
    "<font color='black'>In WordNet, nouns and verbs are organized by DAGs (or hierarchies), while adjectives and adverbs are organized in terms of antonymy, not DAGs. So, it's not possible to compute the LCH between two words with different POS, but it is still possible to compute their similarity. \n",
    "\n",
    "This next matrix displays similarities between words with different POS, including nouns, verbs, adjectives, and adverbs.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LsSynNames = ('cat.n.01', 'run.v.01', 'fly.v.01', 'red.a.01', 'low.a.01', 'slowly.r.01')\n",
    "LSyns = [wn.synset(s) for s in LsSynNames]\n",
    "LLnSim = [[wn.path_similarity(ss, ss2) for ss2 in LSyns] for ss in LSyns] # double loop, calc similarities for all synset pairs\n",
    "df = pd.DataFrame(LLnSim, index=LsSynNames, columns=LsSynNames)\n",
    "df.style.background_gradient(cmap='coolwarm').set_precision(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='black'>Potentially, word similarities could be aggregated at a level of phrases, sentences, and documents to score similarities among documents or between a search phrase and a corpus. A major drawback of WordNet is that experts need to maintain this DAG and its senses manually, which is why WordNet has a limited vocabulary and associated senses. For example, WordNet does not include emojis and memes, although they have gained an important role in communication. \n",
    "    \n",
    "Even so, WordNet can be a powerful DAG in a specific setting. For example, an online retailer could use WordNet to build a graph of its products, their components, and their descriptions. After establishing a similarity metric, such a DAG could later be used in product recommendation algorithms.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n",
    "\n",
    "# **Practice**\n",
    "\n",
    "<font color='black'>Now you will practice evaluating the similarity between different senses of the same word.\n",
    "\n",
    "As you work through these tasks, check your answers by running your code to see if you've gotten the correct result. If you get stuck on a task, click the solution dropdown menu to see a hint. Click again to see the answer.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Find LCH between the *animal* sense and the *emblem* sense of the word `eagle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details><summary><font color=#B31B1B>▶ </font>See <b>solution</b>.</summary>\n",
    "        <b>Hint:</b> First, you need to list all synsets of the lemma <code>eagle</code> and review their definitions. Then pick the best matching synsets and compute <code>lowest_common_hypernyms()</code> as was done above.\n",
    "        <details><summary><font color=#B31B1B>ᐅ </font>One more click for a <b>solution</b>.</summary>\n",
    "            <pre class=\"ec\">\n",
    "_ = [print('>', ss.name(), ':', ss.definition()) for ss in wn.synsets('eagle')]\n",
    "ss1, ss2 = wn.synset('eagle.n.04'), wn.synset('eagle.n.01')\n",
    "ss1.lowest_common_hypernyms(ss2)\n",
    "            </pre>\n",
    "        </details>\n",
    "    </details> \n",
    "</font>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Compute similarity between the *musical tone* sense  and the *act of false explanation* sense of the word `color`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details><summary><font color=#B31B1B>▶ </font>See <b>solution</b>.</summary>\n",
    "        <b>Hint:</b> First, you need to list all synsets of the lemma <code>eagle</code> and review their definitions. Then pick the best matching synsets and compute <code>path_similarity()</code> as was done above.\n",
    "        <details><summary><font color=#B31B1B>ᐅ </font>One more click for a <b>solution</b>.</summary>\n",
    "            <pre class=\"ec\">\n",
    "_ = [print('>', ss.name(), ':', ss.definition()) for ss in wn.synsets('color')]\n",
    "ss1, ss2 = wn.synset('color.n.03'), wn.synset('color.v.05')\n",
    "wn.path_similarity(ss1, ss2)\n",
    "            </pre>\n",
    "        </details>\n",
    "    </details> \n",
    "</font>\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
