{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part One of the Course Project**\n",
    "In this project you will build a RAKE-based similarity metric and use it to find presidential inaugural speeches, which are most similar to the given speech.\n",
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9ae4ff4140a2d387a32895ddf8d8e78",
     "grade": false,
     "grade_id": "cell-3b1273219075bd6c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# **Setup**\n",
    " \n",
    "Reset the Python environment to clear it of any previously loaded variables, functions, or libraries. Then, import the libraries and corpora needed for this project. In this project you will build a RAKE-based similarity metric and use it to find presidential inaugural speeches, which are most similar to the given speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "615dc66e54dd9a8b103908d5ebbb7074",
     "grade": false,
     "grade_id": "cell-1512331266be4895",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2005-Bush.txt', '2009-Obama.txt', '2013-Obama.txt', '2017-Trump.txt', '2021-Biden.txt']\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "from IPython.core.interactiveshell import InteractiveShell as IS\n",
    "IS.ast_node_interactivity = \"all\"    # allows multiple outputs from a cell\n",
    "import numpy as np, pandas as pd, nltk, plotly.express as px, numpy.testing as npt, unittest\n",
    "from rake_nltk import Rake, Metric\n",
    "from numpy.testing import assert_equal as eq, assert_almost_equal as aeq\n",
    "from colorunittest import run_unittest\n",
    "\n",
    "pd.set_option('max_colwidth', 0, 'max_columns', 10)\n",
    "\n",
    "_ = nltk.download(['inaugural'], quiet=True)\n",
    "FIDs = nltk.corpus.inaugural.fileids()[:59]  # load file IDs (incl. 2021-Biden). This list grows over years\n",
    "print(FIDs[-5:])   # a few most recent presidential speech file names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ac0f989a0f08502161f5710da4a6fb4",
     "grade": false,
     "grade_id": "cell-3fb6faa07e9f4c80",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Just like any other NLTK corpus, a presidential speech can be accessed via `nltk.corpus.inaugural.raw()` method, which takes a file id of the speech and returns raw text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94f7b147957e2af7668484175f924c25",
     "grade": false,
     "grade_id": "cell-10c5f2cb1b16bef1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My fellow citizens:\n",
      "\n",
      "I stand here today humbled by the task before us, grateful for the trust you have bestowed, mindful of the sacrifices borne by our ancestors. I thank President Bush for his servic\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.inaugural.raw('2009-Obama.txt')[:200])  # inaugural speech from Obama, 2009"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4eec9bcacba03dbb9f7aff0a7b88bb05",
     "grade": false,
     "grade_id": "cell-0f3155f24068bc9b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Ranking Related Documents With RAKE Keyword Scores\n",
    "\n",
    "## Task 1\n",
    "\n",
    "\n",
    "Complete the `Corpus2Keywords()` function, which takes an NLTK file ID and returns a Pandas DataFrame of RAKE-extracted keywords as indices and their scores as column values. **Remove all duplicated rows from the Pandas DataFrame**. Later you will use these keywords to match keywords from a paired corpus and average their corresponding scores. The function's [docstring](https://www.python.org/dev/peps/pep-0257/) outlines the steps to implement. A call to `Rake()` will require a few lines of code, which we did earlier in the video and the associated Jupyter notebooks.\n",
    "\n",
    "Example. The `Corpus2Keywords('2009-Obama.txt').head(3)` should return\n",
    "\n",
    "|keyword|score|\n",
    "|-|-|\n",
    "|**stale political arguments**|9.000000|\n",
    "|**use energy strengthen**|8.500000|\n",
    "|**would rather cut**|8.333333|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#version to work on\n",
    "\n",
    "def Corpus2Keywords(fid:'NLTK file_id'='2009-Obama.txt') -> pd.DataFrame:\n",
    "    ''' The function takes file id and retrieves inaugural raw text. \n",
    "        It then applies Rake with \"degree to frequency ratio\" metric and language=\"english\" to retrieve \n",
    "        keywords from 1 to 3 word tokens long and their Rake scores (returned in score-decreasing order).\n",
    "        These are then wrapped into a dataframe with \"keyword\" as index and \"score\" as a column.\n",
    "    Input: fid: NLTK file ID\n",
    "    Returns: duplicate-free dataframe with keywords as indices (index \"keyword\") \n",
    "                and their scores in the column \"score\" '''\n",
    "    # YOUR CODE HERE\n",
    "    text = nltk.corpus.inaugural.raw('2009-Obama.txt') \n",
    "    return text[:200]\n",
    "    #raise NotImplementedError()\n",
    "    #return df\n",
    "\n",
    "#df1 = Corpus2Keywords('2009-Obama.txt')\n",
    "#df1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My fellow citizens:\\n\\nI stand here today humbled by the task before us, grateful for the trust you have bestowed, mindful of the sacrifices borne by our ancestors. I thank President Bush for his servic'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus2Keywords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do this last Remove all duplicated rows from the Pandas DataFrame\n",
    "head 3 should give you "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bd4c6c90ec29567de18e6adb12392f8",
     "grade": false,
     "grade_id": "Corpus2Keywords_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def Corpus2Keywords(fid:'NLTK file_id'='2009-Obama.txt') -> pd.DataFrame:\n",
    "    ''' The function takes file id and retrieves inaugural raw text. \n",
    "        It then applies Rake with \"degree to frequency ratio\" metric and language=\"english\" to retrieve \n",
    "        keywords from 1 to 3 word tokens long and their Rake scores (returned in score-decreasing order).\n",
    "        These are then wrapped into a dataframe with \"keyword\" as index and \"score\" as a column.\n",
    "    Input: fid: NLTK file ID\n",
    "    Returns: duplicate-free dataframe with keywords as indices (index \"keyword\") \n",
    "                and their scores in the column \"score\" '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return df\n",
    "\n",
    "df1 = Corpus2Keywords('2009-Obama.txt')\n",
    "df1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f9d8c00096217b862409b9bf401792a",
     "grade": true,
     "grade_id": "Corpus2Keywords_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST & AUTOGRADE CELL\n",
    "@run_unittest\n",
    "class Test_Corpus2Keywords(unittest.TestCase):\n",
    "    def test_00(self): eq(type(df1), pd.DataFrame)\n",
    "    def test_01(self): eq(df1.shape, (79,1))\n",
    "    def test_02(self): eq(df1.index.name, 'keyword')     # check name of dataframe index\n",
    "    def test_03(self): eq(list(df1.columns), ['score'])   # check score column name\n",
    "    def test_04(self): eq(df1.head(3).reset_index().values.tolist(), \n",
    "         [['stale political arguments', 9.], ['use energy strengthen', 8.5], ['would rather cut', 8.333333333333334]])\n",
    "    def test_05(self): eq(df1.max()[0], 9.) # check max Rake score\n",
    "    def test_06(self): eq(df1.loc['stale political arguments'][0], 9.) # check Rake score of a phrase\n",
    "    def test_07(self): eq(df1.loc['use energy strengthen'][0], 8.5)    # check Rake score of another phrase\n",
    "    def test_08(self): eq(df1.sum()[0], 344.71273638642054)  # check sum of all Rake scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ca41cad021e5bb88cd233f51d64a599",
     "grade": false,
     "grade_id": "cell-7b0355844ec22cb8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Task 2\n",
    "\n",
    "Here you will apply the metric developed in Task 1 to measure the similarity between two documents based on their matching keywords and their aggregated scores.\n",
    " \n",
    "You need to complete the `KeywordSim()` function, which takes two file IDs, uses `Corpus2Keywords()` to retrieve the associated keywords/scores as dataframes. Assuming indices are named `\"keyword\"`, you can use dataframe's [`.merge()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) method with argument `on='keyword'` to identify rows in both dataframes with matching indices containing keywords. The corresponding scores are averaged as (score1+score2)/2, which can be done with `mean()` method of a dataframe after a merge. This produces an average score for each matched keyword. Finally, you can use the `.sum()` method to sum all average scores.\n",
    " \n",
    "FYI: you can also use [`.join()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html) method (instead of `merge()`) with `lsuffix` set to arbitrary identifying string to avoid two columns with the same name.\n",
    "\n",
    "The function's docstring outlines the steps needed to complete the function. Merger and aggregation can be done in a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-c81805ad12a6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-c81805ad12a6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    .merge() method with argument on='keyword'\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a = .merge()\n",
    "\n",
    ".merge() method with argument on='keyword' \n",
    "to identify rows in both dataframes with matching \n",
    "indices containing keywords. \n",
    "The corresponding scores are averaged as (score1+score2)/2, \n",
    "which can be done with \n",
    "mean() method of a dataframe after a merge. \n",
    "\n",
    "This produces an average score for each matched keyword. \n",
    "Finally, you can use the .sum() method to sum all average scores.\n",
    "\n",
    "FYI: you can also use .join() method (instead of merge()) \n",
    "    with lsuffix set to arbitrary identifying string to avoid \n",
    "    two columns with the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8e0bfc4f8e15ca12b6999e4f5519bc8",
     "grade": false,
     "grade_id": "KeywordSim_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def KeywordSim(fid1='2009-Obama.txt', fid2='2013-Obama.txt')-> float:\n",
    "    '''The function applies Corpus2Keywords() to each file id to retrieve a dataframe of keywords.\n",
    "    It then merges or inner-joins these dataframes to find only matching keywords. \n",
    "    Each pair of scores from the matched keyword is averaged. All average scores are returned as a sum.\n",
    "    Inputs:\n",
    "        fid1, fid2: NLTK file id for inaugural speeches\n",
    "    Returns:\n",
    "        similarity metric: a sum of average scores from matched keywords in each inaugural speech.\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return SimScore\n",
    "\n",
    "KeywordSim('2009-Obama.txt', '2013-Obama.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9a09cab4282ce0d43970bc67c16bf0b",
     "grade": true,
     "grade_id": "KeywordSim_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST & AUTOGRADE CELL\n",
    "@run_unittest\n",
    "class Test_KeywordSim(unittest.TestCase):\n",
    "    def test_00(self): eq(type(KeywordSim('2009-Obama.txt','2013-Obama.txt')), np.float64)\n",
    "    def test_01(self): aeq(KeywordSim('2009-Obama.txt','2013-Obama.txt'), 13.1032, 3)\n",
    "    def test_02(self): aeq(KeywordSim('2009-Obama.txt','2021-Biden.txt'), 9.3272, 3)\n",
    "    def test_03(self): aeq(KeywordSim('2009-Obama.txt','2017-Trump.txt'), 7.211, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff9ca53a30934a68bec2dad60b08a1e2",
     "grade": false,
     "grade_id": "cell-4ac9647e0fe08284",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Task 3\n",
    " \n",
    "Next, complete the `RankSpeeches()` function. It takes a query file id (`qfid`) and computes its similarity metric with each inaugural speech, which can be retrieved from the NLTK corpus using the FIDs list we created above. This function requires a loop or list comprehension, but can be done in 2-3 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list comperhention\n",
    "return a dataframe\n",
    "you need to build a new one\n",
    "or loo[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64091774d24f529eda0ac3cdccc0ee00",
     "grade": false,
     "grade_id": "RankSpeeches_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def RankSpeeches(qfid='2009-Obama.txt', FIDs=FIDs) -> pd.DataFrame:\n",
    "    '''Given a file ID, this function computes its similarity with every file id in FIDs list.\n",
    "    Inputs:\n",
    "        qfid: query file id of the inaugural speech of interest\n",
    "    Returns:\n",
    "        dataframe of similarity scores (column \"Similarity\") in decreasing order \n",
    "        and the file id (as the dataframe's index \"fid\") from FID which was used to compute \"Similarity\". \n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return df\n",
    "\n",
    "df3 = RankSpeeches(qfid='2021-Biden.txt', FIDs=FIDs)\n",
    "df3.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2539a755f907b295068f4c071c8827e2",
     "grade": true,
     "grade_id": "RankSpeeches_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST & AUTOGRADE CELL\n",
    "@run_unittest\n",
    "class Test_RankSpeeches(unittest.TestCase): \n",
    "    def test_00(self): eq(type(df3), pd.DataFrame)      # check length of a dataframe\n",
    "    def test_01(self): eq(df3.shape, (59,1))            # check length of a dataframe\n",
    "    def test_02(self): eq(df3.index.name, 'fid')        # check index name\n",
    "    def test_03(self): eq(df3.columns, ['Similarity'])  # check column names\n",
    "    def test_04(self): aeq(df3.iloc[0][0], 416.8045, 4) # similarity between query speech and itself\n",
    "    def test_05(self): aeq(df3.iloc[1][0], 23.6311, 4)\n",
    "    def test_06(self): aeq(df3.iloc[:10].mean()[0], 54.2311, 4)\n",
    "    def test_07(self): aeq(df3.sum()[0], 743.5653, 4)\n",
    "    def test_08(self): aeq(df3.diff(-1).fillna(0).sum()[0], 416.8045, 4)  # check decreasing order of a similarities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "511d3d0ab070e8e2852ab8c437e9ac07",
     "grade": false,
     "grade_id": "cell-204428d050744a14",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Visualization\n",
    "\n",
    "There is no task in this section. We are simply building a visualization for similarity scores between the query speech and all remaining speeches. The size of the circle represents the number of words. There is an **unintentional bias** towards longer (in terms of words) inauguration speeches, which are more likely to contain keywords matching many other speeches in this corpus. Thus, `'1841-Harrison.txt'` (largest, with 9165 words) speech is *similar* to many other presidential speeches, and `'1793-Washington.txt'` (smallest, with 147 words) is *dissimilar* to most other speeches. Still, it is interesting to find a speech that is most similar to that of Washington in terms of RAKE keyword scores. Give it a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a1f7b2b9a0373f5e566f16bb0dc8cc1",
     "grade": false,
     "grade_id": "cell-3e3eab838c49c2bb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "qfid = '2021-Biden.txt'\n",
    "df = RankSpeeches(qfid) \n",
    "df = RankSpeeches(qfid, FIDs)   # compute similarity scores between query speech and each speech in FIDs\n",
    "df['nWords'] = [len(nltk.corpus.inaugural.words(fid)) for fid in df.index]  # count of words in each speech\n",
    "\n",
    "# ordered similarities w/o similarity of query speech with itself\n",
    "fig = px.scatter(df[1:], size='nWords', title=qfid, labels={'value':'similarity to query'})\n",
    "fig = fig.update_layout(showlegend=False, margin=dict(l=0,r=0,b=0,t=30), height=300)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
