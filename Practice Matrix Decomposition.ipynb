{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**\n",
    " \n",
    "Reset the Python environment to clear it of any previously loaded variables, functions, or libraries. Then, import the libraries needed to complete the code Professor Melnikov presented in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from IPython.core.interactiveshell import InteractiveShell as IS\n",
    "IS.ast_node_interactivity = \"all\"    # allows multiple outputs from a cell\n",
    "import numpy as np, seaborn as sns, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n",
    "\n",
    "# **Review**\n",
    "\n",
    "## Matrix Factorization (Decomposition)\n",
    "\n",
    "Many advanced algorithms, such as Singular Value Decomposition (SVD) used in topic modeling, use matrix decomposition to find \"simple\" patterns in observed matrix values. Before you move further into these advanced algorithms, you will learn about matrix decompositions &mdash; what they are, when they are applicable, and what to expect as a result.\n",
    "\n",
    "In this notebook you will perform matrix factorization (a.k.a. decomposition) on popular special matrices. \n",
    " \n",
    "You will start by creating a function that takes matrices `A`, `B`, and `C` as arguments and plots them as heatmaps for visual convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotMatMult(A, B, C, figSize=[10,2], nPrecision=2, LsLab=['A', 'B', 'C']) -> None:\n",
    "    '''Plots heatmap subplots with 3 matrices in a row\n",
    "    Inputs:\n",
    "        A,B,C: numpy 2D arrays (i.e. matrices)\n",
    "        figSize: width and height dimensions of the figure to be plotted\n",
    "        nPrecision: number of digits to display in annotations\n",
    "        LsLab: list of labels for the A,B,C matrices  '''\n",
    "    plt.rcParams['figure.figsize'] = figSize\n",
    "    fig, (axA, axB, axC) = plt.subplots(1, 3)\n",
    "    fig.suptitle(f'{LsLab[0]} ⋅ {LsLab[1]} = {LsLab[2]}', fontsize=15)\n",
    "\n",
    "    def Heatmap(Arr:'numpy 2D array', ax:'axis object', sLabel='') -> None:\n",
    "        '''Helper function to plot a single matrix as a heatmap\n",
    "        Inputs:\n",
    "            Arr: matrix to plot as a heatmap, i.e. a 2D array\n",
    "            ax: matplotlib axis object, i.e. a reference to a subplot\n",
    "            sLabel: label for the plot        '''\n",
    "        ax1 = sns.heatmap(Arr, annot=Arr.round(nPrecision), cbar=False, cmap='coolwarm', fmt='',\n",
    "                          annot_kws={\"fontsize\":15}, ax=ax, xticklabels=False, yticklabels=False);\n",
    "        ax1.tick_params(left=False, bottom=False);\n",
    "        ax.set(xlabel=sLabel + ' ' + str(Arr.shape));\n",
    "  \n",
    "    Heatmap(A, axA, LsLab[0])\n",
    "    Heatmap(B, axB, LsLab[1])\n",
    "    Heatmap(C, axC, LsLab[2])\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black\">Create two matrices, `A` and `B`, and use the previous function to plot these with their matrix product (matrix `C`). Think of this equation as:\n",
    "1. Product of $A,B$ to produce $C$, or\n",
    "1. Decomposition (i.e., factorization) of the given matrix $C$ into $A,B$\n",
    " \n",
    "<span style=\"color:black\">This is similar to factorization of a real number. For example, you can factorize $1=a\\cdot 1/a$ for any $a\\ne0$. There are infinitely many $a$ values. In general, $C$ can also be factored into infinitely many matrices. The dimensionality of $A,B$ can change as well, as long as the inner dimensions are the same and outer dimensions match that of the shape of $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(\n",
    "    [[1, 0, 1],\n",
    "     [0, 1, 0]])\n",
    "B = np.array(\n",
    "    [[1, 0, 1, 0],\n",
    "     [0, 1, 0, 1],\n",
    "     [1, 0, 1, 0]])\n",
    "\n",
    "PlotMatMult(A, B, A @ B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "\n",
    "\n",
    "<span style=\"color:black\">Unlike real numbers, matrix multiplication can produce the same output from an infinite combination of factors.\n",
    "<div style=\"margin-top: 20px; margin-bottom: 20px;\">\n",
    "<details style=\"border: 2px solid #ddd; margin-bottom: -2px;\">\n",
    "    <summary style=\"padding: 12px 15px; cursor: pointer; background-color: #eee;\">\n",
    "        <div id=\"button\" style=\"padding: 0px;\">\n",
    "            <font color=#B31B1B>▶ </font> \n",
    "            <b> Example:</b> Infinite Factors in Matrix Multiplication\n",
    "        </div>\n",
    "    </summary>\n",
    "    <div id=\"button_info\" style=\"padding:10px\"> \n",
    "\n",
    "Divide `A` by 2 and multiply `B` by 0.5 to derive matrices `A1` and `B1`. These matrices are different, but their product is still the same matrix `C`. The following statements show that $AB$ is equivalent to $A_1\\cdot B_1$:\n",
    " \n",
    "$$C=AB=A\\cdot 1\\cdot B=A\\cdot (2 \\cdot 0.5)\\cdot B=(A\\cdot 2)\\cdot(0.5\\cdot B)=A_1\\cdot B_1$$\n",
    " \n",
    "Since no change occurs when a matrix is multiplied by scalar 1, the following is true: $AB=A\\cdot 1\\cdot B$. Multiplication by 1 can be rewritten as $2\\cdot0.5$, and each of these scalars can be associated with a matrix to obtain $A\\cdot 1\\cdot B=(A\\cdot 2)\\cdot(0.5\\cdot B)=A_1\\cdot B_1$. Note that by construction, $A\\ne A_1$ and $B\\ne B_1$. \n",
    "\n",
    "You can have infinitely many factors of 1. For example, you can represent 1 as $3\\cdot\\frac{1}{3}$, $-1\\cdot-1$, $10.5\\cdot\\frac{1}{10.5}$ and so on. In general, $1=v\\cdot\\frac{1}{v}$ for any non-zero real value $v$. Since there are infinitely many real numbers, there are infinitely many matrix factors, which will produce the same matrix `C` above. \n",
    "    </div>\n",
    "</details>\n",
    "</div>\n",
    "\n",
    "<span style=\"color:black\">Verify this statement by comparing the plot from multiplying `A1` and `B1` with the above plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1, B1 = 0.5 * A,   2 * B\n",
    "PlotMatMult(A1, B1, A1 @ B1, LsLab=['A1', 'B1', 'C1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black\">Here is one more version of factor matrices `A2` and `B2`, which gives the same `C` as a product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2, B2 = -1 * A,   -1 * B\n",
    "PlotMatMult(A2, B2, A2 @ B2, LsLab=['A2', 'B2', 'C2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black\">You can rescale matrices to derive the same product. But, can you find two different matrices (unrelated via scaling) to derive the same product? The answer is yes, and there is no reason to look for an overly complicated example. The two matrices below give us the zero matrix (full of zero values) if multiplied as $XY$ or $YX$. You should verify this multiplication with pencil and paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(  # Example of different factors yield the same product\n",
    "    [[1, 0], \n",
    "     [0, 0]])\n",
    "Y = np.array(\n",
    "    [[0, 0], \n",
    "     [0, 1]])\n",
    "\n",
    "PlotMatMult(X, Y, X @ Y, figSize=[10,1.5], LsLab=['X', 'Y', 'X@Y'])\n",
    "PlotMatMult(Y, X, Y @ X, figSize=[10,1.5], LsLab=['Y', 'X', 'Y@X'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Matrices\n",
    "\n",
    "\n",
    "<span style=\"color:black\">You may already know many numbers with special properties, such as $a * 0$, an additive identity, which does not change another summand, i.e. $0+a=a+0=a$ for any number $a * 1$, a multiplicative identity, which does not change another multiplicative factor, i.e., $1\\cdot a=a\\cdot1=a$ for any number $a$.\n",
    " \n",
    "<span style=\"color:black\">There are matrices with similar properties. However, the world of special matrices is far more diverse.\n",
    "<div style=\"margin-top: 20px; margin-bottom: 20px;\">\n",
    "<details style=\"border: 2px solid #ddd; margin-bottom: -2px;\">\n",
    "    <summary style=\"padding: 12px 15px; cursor: pointer; background-color: #eee;\">\n",
    "        <div id=\"button\" style=\"padding: 0px;\">\n",
    "            <font color=#B31B1B>▶ </font> \n",
    "            <b> More About:</b> Special Matrix Types\n",
    "        </div>\n",
    "    </summary>\n",
    "    <div id=\"button_info\" style=\"padding:10px\"> \n",
    "\n",
    "1. A **zero** matrix is an additive identity, assuming matching dimensions. In this matrix all values are zeros but dimensions can vary.\n",
    "1. An **identity** matrix is a multiplicative identity, assuming matching inner dimensions. This is a square matrix of varying dimensions with ones on diagonal and zeros otherwise.\n",
    "1. A matrix of ones, where all values are ones.\n",
    "1. A **diagonal** line or elements in a matrix includes all elements with matching row/column indices. So, in a matrix $[a_{ij}]$, $a_{ii}$ are diagonal elements, and other elements are off-diagonal.\n",
    "1. A **symmetric** matrix where all values are the same about the diagonal line or elements.\n",
    "    1. A symmetric matrix must be square, i.e., have the same number of rows and columns.\n",
    "    1. A symmetric matrix has many amazing properties that ease operations on it, such as factorization into two matrices.\n",
    "1. A **diagonal** matrix is a matrix with zeros off-diagonal &mdash; above and below the diagonal values. Diagonal values are those with equal indices, but the matrix itself does not need to be square. \n",
    "    1. Ex. Let $A:=[a_{ij}]_{2\\times4}$, i.e., a matrix with two rows and four columns and elements $a_{ij}$. Then $A$ is diagonal, if $a_{ij}=0,\\forall i\\ne j$, i.e., for all values with non-equal indices being zeros. The zero matrix is also diagonal by this definition.\n",
    "    </div>\n",
    "</details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Zero matrix, np.zeros((2,4)):\\n', np.zeros((2,4), dtype=int))  # similar functionality to a number 0\n",
    "print('Identity matrix, np.identity((2,4)):\\n', np.eye(3, dtype=int)) # similar functionality to a number 1\n",
    "print('Matix of ones, np.ones((2,4)):\\n', np.ones((2,4), dtype=int))    \n",
    "print('Symmetric matrix, B.T @ B:\\n', B.T @ B)                        # symmetric about its diagonal line. It's always square\n",
    "print('Diagonal matrix, np.diag([1,2,3]):\\n', np.diag([1,2,3]))       # diagonal matrices are symmetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthogonal and Orthonormal Vectors\n",
    "\n",
    "<span style=\"color:black\">**Orthogonal** (or perpendicular) vectors are defined as those that give a zero in a dot product. So $a\\top:=[1,0]$ and $b\\top:=[0,-1]$ are orthogonal, since their dot product is zero. Recall that mathematically you always represent vectors vertically, so you use a transposition to indicate that $a$ is a vertical vector, not a horizontal one you display. The (Euclidean) length of $a$ is 1, but length of $b$ is 7. If you scale $b$ as $\\hat b:=b/\\text{length}(b)=[-1,0]$, you derive another unit-length vector. Now, these two vectors are not just orthogonal, but **orthonormal**. \n",
    " \n",
    "Now, a matrix with orthogonal vectors as columns is orthogonal. Likewise, a matrix with orthonormal vectors as columns is orthonormal. If you multiply an orthogonal matrix by its own transpose, you derive a diagonal matrix (with possibly non-zero values on diagonal). If you multiply an orthonormal matrix by its own transpose, you derive an identity matrix. This is because diagonal elements are dot products of each column with itself, which gives a value 1. Confirm this by computing the dot product $a\\bullet a$.\n",
    " \n",
    "Define two orthonormal vectors, $x$ and $y$, and package them as columns of matrix $Z$ using column concatenation operation in NumPy, [`np.c_`](https://numpy.org/doc/stable/reference/generated/numpy.c_.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,0])   # unit-length vector along x-axis in 2D Cartesian coordinates\n",
    "y = np.array([0,-1])  # unit-length vector along y-axis in 2D Cartesian coordinates\n",
    "Z = np.c_[x,y]        # x and y are columns in matrix Z\n",
    "PlotMatMult(Z, Z.T, Z @ Z.T, figSize=[10,1.5], LsLab=['Z', 'Z.T', 'Z @ Z.T'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black\">There are infinitely many orthogonal matrices, i.e., matrices that have orthogonal column vectors. Use [`ortho_group.rvs`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ortho_group.html) to generate a random orthogonal matrix, $Z$ and then verify that it produces an identity matrix (up to a tiny numerical error) by multiplying $Z$ with its own transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ortho_group\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "Z = ortho_group.rvs(dim=3, random_state=0)   # creates some orthogonal matrix\n",
    "PlotMatMult(Z, Z.T, Z @ Z.T, figSize=[10,1.5], LsLab=['Z', 'Z.T', 'Z @ Z.T'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n",
    "\n",
    "# **Optional Practice**\n",
    "Now, equipped with these concepts and tools, you will tackle a few related tasks.\n",
    "\n",
    "As you work through these tasks, check your answers by running your code in the *#check solution here* cell, to see if you’ve gotten the correct result. If you get stuck on a task, click the See **solution** drop-down to view the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    " \n",
    "Define $Z:=[0]_{5\\times 9}$, i.e. a $5\\times 9$ zero matrix. Then define $U:=[1]$ as the matrix of ones of the appropriate size. Then define $F:=5U$ as 5 times $U$. Then define $I$ as an identity matrix of the appropriate size. Finally, compute matrix $A:=((Z + F) \\odot U) \\cdot I$, where $\\odot$ is the Hadamard (i.e., element-wise) product and $\\cdot$ is the usual matrix product. Is $A$ symmetric or diagonal?\n",
    " \n",
    "P.S. $\\odot, \\oslash, \\otimes, \\oplus, \\ominus$ are often used in textbooks and publications to denote element-wise operations between vectors or between matrices.\n",
    "\n",
    "<b>Hint:</b> Use NumPy operations from the examples above to create these matrices. In order to identify the \"appropriate\" dimensions of each matrix, write down the final equation and work backwards noting that addition requires both matrices to have the same size and matrix multiplication requires inner dimensions to match. Also, check precise definitions of symmetric, diagonal and identity matrices above. Do any properties fail these definitions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color=#606366>\n",
    "    <details><summary><font color=#B31B1B>▶ </font>See <b>solution</b>.</summary>\n",
    "$A$ is a matrix of element values 5. Since it is not square, it cannot be symmetric. Diagonal matrices do not need to be square, but they must have zeros above an below diagonal values.\n",
    "            <pre>\n",
    "Z = np.zeros((5, 9), dtype=int)\n",
    "U = np.ones(Z.shape, dtype=int)\n",
    "F = 5 * U\n",
    "I = np.eye(Z.shape[1])\n",
    "A = ((Z + F) * U) @ I\n",
    "A\n",
    "</pre>\n",
    "</details> \n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    " \n",
    "Define $B$ as a top left submatrix of $I$ of the appropriate size to compute $C:=U+9B$. Is $C$ symmetric, diagonal or identity?\n",
    "\n",
    "Note: top left $n\\times p$ submatrix of the matrix $X$ is the block (or submatrix) of contiguous $n$ leftmost rows and $n$ topmost columns.\n",
    "\n",
    "<b>Hint:</b> Just like above deduce the shape of all matrices from the final equation. Also, check precise definitions of symmetric, diagonal and identity matrices above. Do any properties fail these definitions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color=#606366>\n",
    "    <details><summary><font color=#B31B1B>▶ </font>See <b>solution</b>.</summary>\n",
    "$C$ is not symmetric, since it's not an even square, and not diagonal, since off-diagonal values are not zeros. For the same reasons, it is not an identity matrix.\n",
    "            <pre>\n",
    "B = I[:U.shape[0], :U.shape[1]]  # ensures equal number of rows/columns between U and I2\n",
    "C = U + 9*B\n",
    "C\n",
    "</pre>\n",
    "</details> \n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    " \n",
    "Compute $D_1:=C^\\top C$ and $D_2:=C C^\\top$ as matrix multiplications. Are any of the resulting matrices symmetric, diagonal, or identity?\n",
    "\n",
    "<b>Hint:</b> Look up the transpose operation above for NumPy matrices. Also, check precise definitions of symmetric, diagonal and identity matrices above. Do any properties fail these definitions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details><summary><font color=#B31B1B>▶ </font>See <b>solution</b>.</summary>\n",
    "$D_1,D_2$ are symmetric because they are square and have matching elements in positions symmetric about the diagonal line. However, these are not diagonal matrices and not identity matrices because they fail definitions of having zeros above and below the diagonal line.\n",
    "            <pre>\n",
    "D1 = C.T @ C\n",
    "D2 = C @ C.T\n",
    "D1\n",
    "D2\n",
    "</pre>\n",
    "</details> \n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    " \n",
    "Define $U_2$ as a top left submatrix of $U$ of the appropriate size. Then compute $Y:=(D_2-27U_2)/81$. Is $Y$ symmetric, diagonal, or identity?\n",
    "\n",
    "<b>Hint:</b> Again, work backwards from the final equation to determine the appropriate dimensions of each matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color=#606366>\n",
    "    <details><summary><font color=#B31B1B>▶ </font>See <b>solution</b>.</summary>\n",
    "$Y$ is symmetric, diagonal and identity because it satisfies each of these definitions (see above). \n",
    "            <pre>\n",
    "U2 = U[:D2.shape[0], :D2.shape[1]]\n",
    "(D2 - 27*U2)/81\n",
    "</pre>\n",
    "</details> \n",
    "</font>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
