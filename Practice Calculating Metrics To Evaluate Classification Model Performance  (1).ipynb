{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**\n",
    " \n",
    "Reset the Python environment to clear it of any previously loaded variables, functions, or libraries. Then, import the libraries needed to complete the code Professor Melnikov presented in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from IPython.core.interactiveshell import InteractiveShell as IS\n",
    "IS.ast_node_interactivity = \"all\"    # allows multiple outputs from a cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06137b45431b25fa4a38feb071e95ea5",
     "grade": false,
     "grade_id": "cell-d11e91de15292b9a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n",
    "\n",
    "# **Review**\n",
    "\n",
    "<span style=\"color:black\">This notebook will contain a review of feature engineering and model training / evaluation on cosine similarity features. You have done this before, and a more detailed explanation is available in past videos and Jupyter notebooks. This notebook will then move onto using metrics to evaluate the confusion matrix.\n",
    "    \n",
    "<span style=\"color:black\">Begin by defining a cosine similarity function and loading the Word2Vec model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48770e18c1dadba89df627020e697d7c",
     "grade": false,
     "grade_id": "cell-a1348d899fa32fa6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, nltk, seaborn as sns, matplotlib.pyplot as plt\n",
    "import plotly.express as px, plotly.graph_objects as go\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "CosSim = lambda x, y: x @ y / (x @ x)**0.5 / (y @ y)**0.5  # our own implementation of cosine similarity\n",
    "\n",
    "# Dictionary-like object. key=word (string), value=trained embedding coefficients (array of numbers)\n",
    "%time wv = KeyedVectors.load_word2vec_format('glove-wiki-gigaword-50.gz')  # ~20 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b6529f1f76066fbbfaa41243b6ae126",
     "grade": false,
     "grade_id": "cell-482f6684b9f695de",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<span style=\"color:black\">Next, load names and drop those that are not in the Word2Vec model. Balance the labels in the dataset by downsampling the longer list of names to the size of the shorter list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4df6016a262f7e2c3d520adf00f6ba1d",
     "grade": false,
     "grade_id": "cell-a929cb590a4c4f3f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "_ = nltk.download(['names'], quiet=True)\n",
    "LsM = [name.strip().lower() for name in nltk.corpus.names.words('male.txt')]\n",
    "LsF = [name.strip().lower() for name in nltk.corpus.names.words('female.txt')]\n",
    "\n",
    "# Balance observations in two classes. So, a random draw has 50% chance of being from either class.\n",
    "np.random.seed(0)\n",
    "LsF = sorted(np.random.choice(LsF, size=len(LsM), replace=False))\n",
    "LsM2, LsF2 = [s for s in LsM if s in wv], [s for s in LsF if s in wv]\n",
    "LsM2 = np.random.choice(LsM2, size=min(len(LsM2), len(LsF2)), replace=False).tolist()\n",
    "LsF2 = np.random.choice(LsF2, size=min(len(LsM2), len(LsF2)), replace=False).tolist()\n",
    "print(f'{len(LsM2)} male names:  ', LsM2[:8])\n",
    "print(f'{len(LsF2)} female names:', LsF2[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43e7642db0b75c15bf47ef02e1460ce4",
     "grade": false,
     "grade_id": "cell-44fa8aa94cc409f0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## **Cosine Similarity**\n",
    "\n",
    "<span style=\"color:black\">Now, build the cosine similarity feature that measures the relation of each name to the word \"feminine.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66fa6af166fae774e81076c8edc16d0b",
     "grade": false,
     "grade_id": "cell-60c67cf4c6b4235f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# cosine similarity to query function, i.e. it returns a function which can be further evaluated\n",
    "CS2Q = lambda sQuery='man': lambda sName: CosSim(wv[sName], wv[sQuery]) if sName in wv else 0 \n",
    "df = pd.DataFrame(LsF2 + LsM2, columns=['Name'])\n",
    "df['Y'] = [1] * len(LsF2) + [0] * len(LsM2)   # create numeric labels for names\n",
    "df['CS2F'] = df.Name.apply(CS2Q('feminine'))   # for each name compute cosine similarity to female query word\n",
    "df = df.sort_values('CS2F', ascending=False).set_index('Name')\n",
    "df.T.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b3fd7d35def3dca741375040c138ecc",
     "grade": false,
     "grade_id": "cell-3d9b094396dbda17",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## **Logistic Regression Model**\n",
    "\n",
    "<span style=\"color:black\">Build a logistic regression model on the single input feature and the binary output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4039b15e066d611e7b70627989d69277",
     "grade": false,
     "grade_id": "cell-24f5c70d76317b37",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tX, vX, tY, vY = train_test_split(df.drop('Y', axis=1), df.Y, test_size=0.2, random_state=0)\n",
    "lr = LogisticRegression(random_state=0).fit(tX, tY)    # create a model; fit a model to compute model parameters\n",
    "print(f'Accuracy = fraction of correct predictions: {lr.score(vX, vY):.3f}') # report out of sample accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "675637aba0a71b953131de9e81417b0f",
     "grade": false,
     "grade_id": "cell-3e9cdec1d4f96bc4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## **Confusion Matrix**\n",
    "\n",
    "<span style=\"color:black\">Construct a simple confusion matrix with the correct classifications on the diagonal and misclassified examples off the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "438be073aceb8b3be60af9004b6e0655",
     "grade": false,
     "grade_id": "cell-66cd804dccd8bae7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pY = lr.predict(vX)\n",
    "cm = confusion_matrix(y_true=vY, y_pred=pY, labels=[0,1])\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ec97c1ac685da21cbca8d6aaa28618c",
     "grade": false,
     "grade_id": "cell-3907d72e7eb7ea93",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<span style=\"color:black\">You will now manually calculate the metrics discussed in the video. \n",
    "    \n",
    "<span style=\"color:black\"><b>Note:</b> scikit-learn has convenient functions to compute these metrics individually or all together in a single report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd2141c7f540ebd07cb4c295da2dfc5b",
     "grade": false,
     "grade_id": "cell-45113276f49e3c19",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "(TN, FP), (FN, TP) = cm\n",
    "nTot = cm.sum()\n",
    "nCorrect = TP + TN   # Total correct predictions (pos or neg); diagonal elements\n",
    "nTrueNeg = TN + FP   # Total true negative (male) cases; top row\n",
    "nTruePos = FN + TP   # Total true poitive (female) cases; bottom row\n",
    "nPredNeg = TP + FP   # Total predicted negative (male) cases; 1st column\n",
    "nPredPos = TP + FP   # Total predicted positive (female) cases; 2nd column\n",
    "\n",
    "nAcc = nCorrect / nTot\n",
    "nFPR = FP / nTrueNeg # False pos rate, 1-specificity, Type-1 Error\n",
    "nTPR = TP / nTruePos # True pos rate, recall, sensitivity, Type-II error\n",
    "nPPV = TP / nPredPos # Pos predictive value, precision, 1-false discovery rate\n",
    "nNPV = TN / nPredNeg # Neg predictive value\n",
    "\n",
    "print(f'Acc = {nAcc:.3F}')  # Fraction of correct predictions\n",
    "print(f'FPR = {nFPR:.3F}')  # \n",
    "print(f'TPR = {nTPR:.3F}')  # Fraction of true positives that were correctly predicted\n",
    "print(f'PPR = {nPPV:.3F}')  # Fracion of predicted positives, which are correct \n",
    "print(f'F1  = {2 * nPPV * nTPR/ (nPPV + nTPR):.3F}') # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ecb8093dbabf69f84ca544e0e9343aa",
     "grade": false,
     "grade_id": "cell-31a2f4612725dca1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "\n",
    "## **Build a Receiver Operating Characteristic**\n",
    "\n",
    "<span style=\"color:black\"> Next, you will build a Receiver Operating Characteristic ([ROC](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html?highlight=eceiver%20operating%20characteristic)) curve.\n",
    "\n",
    "<div id=\"blank_space\" style=\"padding-top:20px\">\n",
    "    <details>\n",
    "        <summary>\n",
    "            <div id=\"button\" style=\"color:white;background-color:#de2424;padding:10px;border:3px solid #B31B1B;border-radius:30px;width:140px;text-align:center;float:left;margin-top:-15px\"> \n",
    "                <b>ROC Curve → </b>\n",
    "            </div>\n",
    "        </summary>\n",
    "        <div id=\"button_info\" style=\"padding:20px;background-color:#eee;border:3px solid #aaa;border-radius:30px;margin-left:25px;\">\n",
    "            <p style=\"padding:15px 2px 2px 2px\">\n",
    "                There are various versions of the <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics\">ROC</a> curve, but a popular version plots true positive rate (TPR) versus false positive rate (FPR). For every value of you probability threshold, plot a single point with coordinates (TPR, FPR). There are as many thresholds as observations in the validation sample. These points are connected with step functions to derive the orange curve. The dashed line indicates the prediction of the random model (which randomly assigns labels to observations). The random model is your benchmark. </p>\n",
    "        </div> \n",
    "    </details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c62238da89544c259a933e036b0c31d",
     "grade": false,
     "grade_id": "cell-7f341cff3d565948",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "pY1 = lr.predict_proba(vX)[:,1]   # probability of class 1 only\n",
    "AUC = roc_auc_score(y_true=vY, y_score=pY1)\n",
    "fpr, tpr, thresholds = roc_curve(y_true=vY, y_score=pY1)\n",
    "\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='Random guess model');\n",
    "plt.plot(fpr, tpr, marker='', label='Logistic regression model');\n",
    "plt.xlabel('False Positive Rate (FPR)');\n",
    "plt.ylabel('True Positive Rate (TPR)');\n",
    "plt.text(0, 0.8, f'AUC={AUC:.2f}', fontsize=15);\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve');\n",
    "plt.legend();\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98f3f8ec3c50170b4bb1b46a40abde46",
     "grade": false,
     "grade_id": "cell-b265165213e18d5e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n",
    "\n",
    "# **Optional Practice**\n",
    "Now, equipped with these concepts and tools, you will tackle a few related tasks.\n",
    "\n",
    "As you work through these tasks, check your answers by running your code in the *#check solution here* cell, to see if you’ve gotten the correct result. If you get stuck on a task, click the See **solution** drop-down to view the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa33f864f01d07049380020c42e9d9dc",
     "grade": false,
     "grade_id": "cell-f5a11d1225686026",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Task 1\n",
    " \n",
    "Copy the `df` dataframe into `df1` and add a columns `CS2lady`. This uses the `CS2Q()` function to compute cosine similarity distances from the given name (in each row) to the target word `lady`. Similarly, add columns `CS2woman`, `CS2female`, `CS2guy`, `CS2girl`, and `CS2robert`.\n",
    "\n",
    "<b>Hint:</b> The code above should guide you through these steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color=#606366>\n",
    "    <details><summary><font color=#b31b1b>▶ </font>See <b>solution</b>.</summary>\n",
    "<pre>\n",
    "df1 = df.copy()\n",
    "df1['CS2lady'] = df.reset_index().Name.apply(CS2Q('lady')).values\n",
    "df1['CS2woman'] = df.reset_index().Name.apply(CS2Q('woman')).values\n",
    "df1['CS2female'] = df.reset_index().Name.apply(CS2Q('female')).values\n",
    "df1['CS2guy'] = df.reset_index().Name.apply(CS2Q('guy')).values\n",
    "df1['CS2girl'] = df.reset_index().Name.apply(CS2Q('girl')).values\n",
    "df1['CS2robert'] = df.reset_index().Name.apply(CS2Q('robert')).values\n",
    "df1.T\n",
    "</pre>\n",
    "</details> \n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8047dd293ee6a70ef4c5506f6f8e070e",
     "grade": false,
     "grade_id": "cell-d522bebd14ec1e0f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Task 2\n",
    "\n",
    "Build a logistic regression model based on the features you created. Then compute the confusion matrix.\n",
    "\n",
    "<b>Hint:</b> See the code above or in the previous Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color=#606366>\n",
    "    <details><summary><font color=#b31b1b>▶ </font>See <b>solution</b>.</summary>\n",
    "<pre>\n",
    "tX, vX, tY, vY = train_test_split(df1.drop('Y', axis=1), df1.Y, test_size=0.2, random_state=0)\n",
    "lr1 = LogisticRegression(random_state=0).fit(tX, tY)   # create a model; compute model parameters\n",
    "print(f'Accuracy = fraction of correct predictions: {lr1.score(vX, vY):.3f}') # report out of sample accuracy\n",
    "pY = lr1.predict(vX**2)\n",
    "cm = confusion_matrix(y_true=vY, y_pred=pY, labels=[0,1])\n",
    "cm\n",
    "</pre>\n",
    "</details> \n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c659342d01fbd7f371897bdc8951149c",
     "grade": false,
     "grade_id": "cell-2a42445ee43b99a7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Task 3\n",
    "\n",
    "Compute AUC and build a ROC curve for the model you built.\n",
    "\n",
    "<b>Hint:</b> See code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color=#606366>\n",
    "    <details><summary><font color=#b31b1b>▶ </font>See <b>solution</b>.</summary>\n",
    "<pre>\n",
    "pY1 = lr1.predict_proba(vX)[:,1]   # probability of class 1 only\n",
    "AUC = roc_auc_score(y_true=vY, y_score=pY1)\n",
    "fpr, tpr, thresholds = roc_curve(y_true=vY, y_score=pY1)\n",
    "\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='Random guess model')\n",
    "plt.plot(fpr, tpr, marker='', label='Logistic regression model')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.text(0, 0.8, f'AUC={AUC:.2f}', fontsize=15)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "</pre>\n",
    "</details> \n",
    "</font>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ddd722b38555b509228df23378b15b3",
     "grade": false,
     "grade_id": "cell-1c9a6e5fdf572e28",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Task 4\n",
    "\n",
    "Try to further improve the model. You can also explore different hyperparameters of [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model.\n",
    "\n",
    "This is an open ended task and has no single specific solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solutions goes here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
