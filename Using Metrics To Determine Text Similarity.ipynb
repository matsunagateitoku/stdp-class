{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part One of the Course Project**\n",
    "In this project, you will develop and apply Jaccard similarity to find similar presidential speeches and apply Hamming distance to find similar viral DNA sequences.\n",
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "adfd83c6c2e656fe2b8d4dc515968dfd",
     "grade": false,
     "grade_id": "cell-a9d40ca3a9daac71",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# **Setup**\n",
    " \n",
    "Reset the Python environment to clear it of any previously loaded variables, functions, or libraries. Then, import the libraries and corpora needed for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10e3cdd974e45178cf8ea6e3ef81e61b",
     "grade": false,
     "grade_id": "cell-afc1076a9a2b7f5a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from IPython.core.interactiveshell import InteractiveShell as IS; IS.ast_node_interactivity = 'all'\n",
    "import nltk, string, pandas as pd, numpy as np, unittest, numpy.testing as npt\n",
    "from colorunittest import run_unittest\n",
    "_ = nltk.download(['inaugural', 'stopwords'], quiet=True) # silently load corpora from NLTK\n",
    "\n",
    "np.set_printoptions(linewidth=10000, precision=4, edgeitems=20, suppress=True) \n",
    "pd.set_option('max_colwidth', 200, 'display.max_rows', 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5fd1aa2ddb0f425c4753c1f510fc2ca9",
     "grade": false,
     "grade_id": "cell-cfc888b2403494cb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Next, load two presidential speeches and the English list of common stop words from the NLTK corpus. `SsPunct` is a list of English punctuation symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eec4669d2349510809d5db337a0359cc",
     "grade": false,
     "grade_id": "cell-fc0ff824cf9b6687",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "LsObama9    = nltk.corpus.inaugural.words('2009-Obama.txt') # Text of Pres Obama's inaugural speech of 2009\n",
    "LsObama13   = nltk.corpus.inaugural.words('2013-Obama.txt') # Text of Pres Obama's inaugural speech of 2013\n",
    "SsStopwords = set(nltk.corpus.stopwords.words('english'))   # list of common English stop words \n",
    "SsPunct     = set(string.punctuation)                       # English punctuation symbols\n",
    "print(LsObama9[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c83bf202cedfb25a5a9d47794cc46d9e",
     "grade": false,
     "grade_id": "cell-a251ff33ed472b88",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## **Task 1**\n",
    "\n",
    "Complete the user defined function (UDF) `JS()`, which takes two sets of string tokens, `A` and `B`, and computes Jaccard similarity between them. The other parameters determine the required preprocessing of these sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60f217a3ad549f3eb268c40e91b781f9",
     "grade": false,
     "grade_id": "JS_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CELL\n",
    "def JS(A=set('ABC'), B=set('ABCD'), Lower=False, Stop=SsStopwords, Punct=SsPunct):\n",
    "    '''Jaccard similarity between sets of string tokens A & B. Evaluate arguments are in order listed.\n",
    "    If denominator is zero, return zero\n",
    "    Inputs:\n",
    "        A, B: two containers (set, list, etc.) with string elements.\n",
    "        Lower: indicates whether lower case should be used before removal of stopwords and punctuation\n",
    "        Stop: container of stopword strings\n",
    "        Punct: container of punctuation strings\n",
    "    Return: Jaccard similarity after preprocessing of A and B\n",
    "    '''\n",
    "    a, b = set(A), set(B)  # initialize a, b (cast to sets, just in case)\n",
    "#     if Lower: a, b = \n",
    "#     if Stop:  a, b = \n",
    "#     if Punct: a, b = \n",
    "    js = None  # final Jaccard similarity score\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c83061b1c6f0791caaf02bb58bbc958",
     "grade": false,
     "grade_id": "cell-57587265327e4cb8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The tests in the cell below can help you troubleshoot specific failing scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e2916790a79743d760e0890efc6c9cf",
     "grade": true,
     "grade_id": "JS_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "ae = npt.assert_equal\n",
    "@run_unittest\n",
    "class Test_JS(unittest.TestCase): # class with methods to test functionality of the JS() function\n",
    "    def test00(self): ae(JS('', 'ABC'), 0)\n",
    "    def test01(self): ae(JS('ABC', ''), 0)\n",
    "    def test02(self): ae(JS('', ''), 0)\n",
    "    def test03(self): ae(JS('ABC', 'ABC'), 1)\n",
    "    def test04(self): ae(JS('ABC', 'ABc'), 0.5)\n",
    "    def test05(self): ae(JS('ABC', 'ABC', Stop='A'), 1)\n",
    "    def test06(self): ae(JS('ABC', 'ABc', Stop='c'), 0.6666666666666666)\n",
    "    def test07(self): ae(JS('ABC', 'ABc', Stop='Cc'), 1)\n",
    "    def test08(self): ae(JS('ABC!', 'ABC', Stop='A'), 1)\n",
    "    def test09(self): ae(JS('ABC!', 'ABc,', Stop='c'), 0.6666666666666666)\n",
    "    def test10(self): ae(JS('ABC!', 'ABc%', Stop='Cc'), 1)\n",
    "    def test11(self): ae(JS('ABC', 'ABC', Lower=True, Stop='A'), 1)\n",
    "    def test12(self): ae(JS('I like NLP'.split(), 'I like nlp'.split()), 0.5)\n",
    "    def test13(self): ae(JS('I like NLP'.split(), 'I like nlp'.split(), Lower=True, Stop={}), 1)\n",
    "    def test14(self): ae(JS('I like NLP'.split(), 'I like nlp'.split(), Lower=True, Stop=['nlp']), 1)\n",
    "    def test15(self): ae(JS('I like NLP'.split(), 'I like nlp'.split(), Lower=False, Stop=['NLP', 'nlp']), 1)\n",
    "    def test16(self): ae(JS(LsObama9, LsObama13, Lower=True, Stop={}, Punct={}),  0.25333333333333335)\n",
    "    def test17(self): ae(JS(LsObama9, LsObama13, Lower=False, Stop={}, Punct={}), 0.24857954545454544)\n",
    "    def test18(self): ae(JS(LsObama9, LsObama13, Lower=True, Punct={}),  0.21112006446414183)\n",
    "    def test19(self): ae(JS(LsObama9, LsObama13, Lower=False, Punct={}), 0.21137586471944658)\n",
    "    def test20(self): ae(JS(LsObama9, LsObama13, Lower=True, Stop={}), 0.2503725782414307)\n",
    "    def test21(self): ae(JS(LsObama9, LsObama13, Lower=False, Stop={}), 0.24571428571428572)\n",
    "    def test22(self): ae(JS(LsObama9, LsObama13, Lower=True), 0.20762368207623683)\n",
    "    def test23(self): ae(JS(LsObama9, LsObama13, Lower=False), 0.20804331013147717)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d8bd8bac76d7f3248f247b8cf52fb3c",
     "grade": false,
     "grade_id": "cell-de583cccd76ef4d8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## **Task 2**\n",
    "\n",
    "Complete UDF `JS_Speech()` and apply UDF `JS()` to compute Jaccard similarity scores for `SsQry` set and each presidential speech in NLTK (i.e. `nltk.corpus.inaugural.fileids()`). The JS score and `fid` of each speech is packaged as a row in Pandas DataFrame object (with a column `JS`). The `fid` value (without `.txt`) is used as the row index. Return results ordered by decreasing `JS`. So, the top speeches are most similar to the `SsQry` with respect to Jaccard similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ad6c7853161c9389b6eacd364699252",
     "grade": false,
     "grade_id": "JS_Speech_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def JS_Speech(SsQry=LsObama9, Lower=True, Stop=SsStopwords, Punct=SsPunct):\n",
    "    '''Compute Jaccard similarity of each presidential inaugural speech with SsQry set of words.\n",
    "    Inputs:\n",
    "      SsQry: a vocabulary, i.e. set of words describing the query document\n",
    "      Lower: indicates whether lower case should be used before removal of stopwords and punctuation\n",
    "      Stop: container of stopword strings\n",
    "      Punct: container of punctuation strings\n",
    "    Return: Dataframe with file id (fid) as row index (labeled as `fid`) and Jaccard score column (labeled `JS`)\n",
    "      Omit `.txt` from fid index values; i.e. use fid index '1993-Clinton' instead of original fid '1993-Clinton.txt'\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fae0d3c217093f9e69f0397b4c357a9c",
     "grade": true,
     "grade_id": "JS_Speech_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "ae = npt.assert_equal\n",
    "@run_unittest\n",
    "class Test_JS_Speech(unittest.TestCase): # class with methods to test functionality of the JS() function\n",
    "    def test00(self): ae(JS_Speech().shape, (59,1))\n",
    "    def test01(self): ae(list(JS_Speech().T.columns[:2]), ['2009-Obama', '2013-Obama'])\n",
    "    def test02(self): ae(JS_Speech().T['2009-Obama'].values, 1)\n",
    "    def test03(self): ae(JS_Speech().iloc[2,0], 0.19166666666666668)\n",
    "    def test04(self): ae(JS_Speech(Lower=False, Stop={}).iloc[2,0], 0.23795620437956205)\n",
    "    def test05(self): ae(JS_Speech(Lower=False, Punct={}).iloc[2,0], 0.2004698512137823)\n",
    "    def test06(self): ae(JS_Speech(Lower=False, Stop={}, Punct={}).iloc[2,0], 0.24147933284989123)\n",
    "    def test07(self): ae(JS_Speech(Lower=True, Stop={}).iloc[2,0], 0.23637759017651575)\n",
    "    def test08(self): ae(JS_Speech(Lower=True, Punct={}).iloc[2,0], 0.19602977667493796)\n",
    "    def test09(self): ae(JS_Speech(Lower=True, Stop={}, Punct={}).iloc[2,0], 0.24009146341463414)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "31762f9fdc547121692c906083f0fa58",
     "grade": false,
     "grade_id": "cell-1e41a5655861434a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Task 3\n",
    "\n",
    "In this task, you are given a Hamming distance UDF `HD()` and a sequence generating UDF `GenSeq()` similar to those you saw in the video. You will apply these functions in Task 3 described below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37c84ba36ce10586946f6e72cef6d21b",
     "grade": false,
     "grade_id": "cell-36c940a907db2cea",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hamming distance UDF\n",
    "HD = lambda s1='ab', s2='ad': sum(ch1 != ch2 for ch1, ch2 in zip(s1, s2)) if len(s1)==len(s2) else np.inf\n",
    "\n",
    "def GenSeq(nLen=10, seed=int(0), LsElements=list('ACGT')):\n",
    "    '''Generate a list of sampled nLen objects listed in LsElements'''\n",
    "    if isinstance(seed, int):        # only integers >=0 are used for seeding\n",
    "        np.random.seed(abs(seed))      # seed random number generator (RNG) if integer seed is provided\n",
    "    return ''.join(np.random.choice(LsElements, nLen, replace=True))\n",
    "\n",
    "GenDNA = lambda nLen=5, seed=0: GenSeq(nLen, seed, list('ACGT'))\n",
    "sQry = GenDNA(100, seed=0)\n",
    "sTgt = GenDNA(200, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "650ff082b0e234cdfc48a441bd9d5d46",
     "grade": false,
     "grade_id": "cell-7456a3322dff361b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Complete the UDF `Marker()`, which takes two same-length strings, query `sQry` and target `sTgt`, and computes returns a \"**marked**\" string `sTgt` where the characters matching to corresponding characters in `sQry` are replaced with `_`. This function is helpful to visually highlight unmatched elements in string `sTgt`. If string lengths differ, UDF returns `''`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27c14423629df34a3989d276d7968127",
     "grade": false,
     "grade_id": "Marker_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def Marker(sQry='ACGG', sTgt='ACGT'):\n",
    "    '''Compares two same-length strings and replaces a character in sTgt with '_' \n",
    "        if it matches the corresponding character in sQry. Else leaves the character as is.\n",
    "    Inputs:\n",
    "      sQry, sTgt: target and query strings\n",
    "    Returns: a string with length of sTgt with some characters replaced with '_'.\n",
    "      If sTgt and sQry have different lengths, UDF returns '' (empty string)\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return sOut  # return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "864846cbc34c382fc06c107809d4d2c7",
     "grade": true,
     "grade_id": "Marker_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "ae = npt.assert_equal\n",
    "@run_unittest\n",
    "class Test_Marker(unittest.TestCase): # class with methods to test functionality of the JS() function\n",
    "    def test00(self): ae(Marker(sQry='ACGG', sTgt='ACGT'), '___T')\n",
    "    def test01(self): ae(Marker(sQry='ACGT', sTgt='ACGT'), '____')\n",
    "    def test02(self): ae(Marker(sQry='ACGGA', sTgt='ACGT'), '')\n",
    "    def test03(self): ae(Marker(sQry='AGT', sTgt='ACGT'), '')\n",
    "    def test04(self): ae(Marker(GenDNA(20, seed=0), GenDNA(20, seed=0)), '____________________')\n",
    "    def test05(self): ae(Marker(GenDNA(20, seed=0), GenDNA(20, seed=1)), 'C_A__C_CTAAC__C_GC_A')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b4130beffb265c2e16a7f1b6a8cc992",
     "grade": false,
     "grade_id": "cell-f139500fc8791c79",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Task 4\n",
    "\n",
    "Now, apply `HD()` and `Marker()` to create UDF `RankHD()`, which takes two strings: query `sQry` and target `sTgt`, of varying lengths. Then, for each substring in `sTgt` with length equal to `len(sQry)`, compute the Hamming distance and the corresponding marked string. This can be done by looping over all substrings in `sTgt`, if such substrings exist. Package the results into two dataframe columns, as described in the function docstring below. \n",
    "\n",
    "This function can be used to find the closest match to `sQry` inside the `sTgt` and is often used by professionals to rank viral samples by their similarity or distance to the bank of known viral strings (which can have varying length samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f05f8fd3f88d59beda05b17df5e26d7",
     "grade": false,
     "grade_id": "RankHD_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def RankHD(sQry='ACGT', sTgt='ACTGTCT'):\n",
    "    '''This UDF uses HD() to rank each substring in sTgt \n",
    "        of length N=len(sQry) with its HD to sQry. \n",
    "        To do that you can iterate over each N-length substrings (i.e. Samples).\n",
    "        For each Sample compute HD(sQry, Sample) and Marker(sQry, Sample).\n",
    "        For example, sTgt='ACTGTCT' has 4 Samples of length 4: ACTG,CTGT,TGTC,GTCT\n",
    "        and Marker('ACGT', 'ACTG') returns '__GT'\n",
    "    Inputs:\n",
    "      sQry, sTgt: strings of not necessarily same length.\n",
    "    Returns:\n",
    "      dataframe of shape M x 2 with columns 'HD' (rank or Hamming distance)\n",
    "      and 'Sample', which contains \n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return df # return dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aea49e98f272fb0398ac1b4af36681e6",
     "grade": true,
     "grade_id": "RankHD_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN CELL TO TEST YOUR CODE\n",
    "ae = npt.assert_equal\n",
    "@run_unittest\n",
    "class Test_RankHD(unittest.TestCase): # class with methods to test functionality of the JS() function\n",
    "    def test00(self): ae(RankHD().shape, (4, 2))\n",
    "    def test01(self): ae(RankHD().iloc[0,:].values.tolist(), [2, '__GT'])\n",
    "    def test02(self): ae(RankHD().iloc[-1,:].values.tolist(), [4, 'ACGT'])\n",
    "    def test03(self): ae(RankHD(sQry='ACTGTCT', sTgt='ACGT').shape, (0, 2))\n",
    "    def test04(self): ae(RankHD(sQry, sTgt).shape, (101, 2))\n",
    "    def test05(self): ae(RankHD(sQry, sTgt).iloc[0,0], 60)\n",
    "    def test06(self): ae(RankHD(sQry, sTgt).iloc[-1,0], 88)\n",
    "    def test07(self): ae(RankHD(sQry, sTgt).iloc[0,1][:10], 'A_CATT__CT')\n",
    "    def test08(self): ae(RankHD(sQry, sTgt).iloc[-1,1][:10], 'ATCATTTTCT')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
