{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "feffd900b13a4e164e4e9fed3b76c436",
     "grade": false,
     "grade_id": "cell-0b9c160fc3a937e4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# **Part Two of the Course Project**\n",
    " \n",
    "In this part of the course project, you will train models to perform binary classification of a dataset containing names and explore various features of your dataset to improve your model. \n",
    "<hr style=\"border-top: 2px solid #606366; background: transparent;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**\n",
    " \n",
    "Reset the Python environment to clear it of any previously loaded variables, functions, or libraries. Then, import the libraries needed to complete this part of the course project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "423e0eb9fe55679b24080d009633e68b",
     "grade": false,
     "grade_id": "cell_import",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from IPython.core.interactiveshell import InteractiveShell as IS\n",
    "IS.ast_node_interactivity = \"all\"    # allows multiple outputs from a cell\n",
    "import pandas as pd, numpy as np, seaborn as sns, matplotlib.pyplot as plt, nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter\n",
    "from numpy.testing import assert_equal as eq, assert_almost_equal as aeq\n",
    "pd.set_option('max_colwidth', 100, 'display.max_rows', 10)\n",
    "import unittest\n",
    "from colorunittest import run_unittest\n",
    "\n",
    "_ = nltk.download(['names'], quiet=True)\n",
    "LsM = nltk.corpus.names.words('male.txt')   # list of strings: male names\n",
    "LsF = nltk.corpus.names.words('female.txt') # list of strings: female names\n",
    "print(f'{len(LsM)} male names:  ', LsM[:8])\n",
    "print(f'{len(LsF)} female names:', LsF[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7d44857d7a7d54e2df3e118f7756ac2",
     "grade": false,
     "grade_id": "cell_setup",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Balance observations in two classes. So, a random draw has 50% chance of either class.\n",
    "rng = np.random.RandomState(0)  # seed random number generator with a number 0 (for reproducibility)\n",
    "LsF = sorted(list(rng.choice(LsF, size=len(LsM), replace=False)))       # shorten the list of female names\n",
    "df = pd.DataFrame(dict(Name=LsF + LsM, Y=[1]*len(LsF) + [0]*len(LsM)) ) # assign labels: 1=female, 0=male\n",
    "df.Name = df.Name.str.lower()   # convert all names to lower case\n",
    "df.set_index('Name', inplace=True)\n",
    "df.T   # display names (as column names) and their labels (0=male, 1=female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "35691d72e16c5ebd4ec018fc72f1f0ca",
     "grade": false,
     "grade_id": "cell-67075aeba16f51da",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "To predict the class of a name, we hypothesize numeric attributes that can be indicative of a gender, given a name. In the video and earlier exercises we tried counting letters in the name. Now, let's count vowel letters with hope that it will help us identify a class for the given name. Since there are equal counts of class names in `df` dataframe, a model that does not use any of the name attributes would be 50% accurate. We are trying to find attributes that will help us outperform this naive benchmark of 50% accuracy on the (test) sample, which the model has not memorized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1dd1302b6314e722d3b0f2d5d731eb7",
     "grade": false,
     "grade_id": "Task1_read",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Task 1. Add numeric feature: a count of vowels\n",
    "\n",
    "In the cell below use `copy()` method to copy `df` to dataframe `df1` and add a column `Vowels` to `df1`. It should contain the count of vowel letters (`'aeiouy'`) in the corresponding name. Here is an example of the updated `df1` for the top two rows:\n",
    "        \n",
    "|Name|Y|Vowels|\n",
    "|-|-|-|\n",
    "|abagail|1|4|\n",
    "|abbe|1|2|\n",
    " \n",
    "FYI: `'y'` (like `'w'`) is sometimes defined as a consonant, but we'll consider it a vowel sound as in words mary, daryl, corey, and others. You can later experiment with which categorization of these letters improves your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fb74c0a3c1ff21d728865fbe6f85913",
     "grade": false,
     "grade_id": "Task1_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "df1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20eb79dfec09ea0a66385c829e17b374",
     "grade": true,
     "grade_id": "Task1_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST & AUTOGRADE CELL\n",
    "@run_unittest\n",
    "\n",
    "class test_task_1(unittest.TestCase):\n",
    "    def test_00(self): \n",
    "        assert 'Vowels' in df1\n",
    "    def test_01(self):    \n",
    "        eq(df1.shape, (5886,2))  # df should contain only columns Y and Vowels\n",
    "    def test_02(self):\n",
    "        eq(df1.query(\"Name=='abagail'\").iloc[0,:].values, (1,4))\n",
    "    def test_03(self):\n",
    "        eq(df1.query(\"Name=='abbe'\").iloc[0,:].values, (1,2))\n",
    "    def test_04(self):\n",
    "        eq(df1.sum().values, [ 2943, 15296])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c13bce8710e300cba52611bda5dc4a8",
     "grade": false,
     "grade_id": "Task2_read",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Task 2. Train and validate logistic regression with Vowels feature\n",
    " \n",
    "Use [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split pandas dataframe `df1` (without `Y` column) and pandas series `Y` (a column from `df1` dataframe) into objects:\n",
    " \n",
    "1. `tX` = a pandas dataframe with a column `Vowels`, a training input feature\n",
    "1. `vX` = a pandas dataframe with a column `Vowels`, a validation input feature\n",
    "1. `tY` = a pandas series, a column `Y`, containing training labels for the corresponding rows in `tX`\n",
    "1. `vY` = a pandas series, a column `Y`, containing validation labels for the corresponding rows in `vX`\n",
    " \n",
    "Then proceed with model fitting and evaluation:\n",
    " \n",
    "1. create a [`LogisticRegression()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) object, `lr`. \n",
    "1. fit it to `tX,tY` using the [`lr.fit()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit) method. \n",
    "1. compute the model accuracy with [`lr.score()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score) method and appropriate input/output arguments\n",
    " \n",
    "If done correctly, your model should score about 61% validation accuracy and 62% training accuracy.\n",
    " \n",
    "To ensure reproducibility of your model results, leave all function arguments at their default values, except:\n",
    " \n",
    "1. set `random_state` to 0 for both functions.\n",
    "1. use `test_size` of 0.2 for the split. That is 20% is allocated to validation sets, `vX,vY`, and 80% is allocated to train sets, `tX,tY`\n",
    " \n",
    "Hint: see previous course videos and Jupyter notebooks for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea59ded6cd85476b5ef3987aa02f3051",
     "grade": false,
     "grade_id": "Task2_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "pd.DataFrame(lr.get_params(deep=True).items()).set_index(0).T  # print model hyperparameters as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9274151fb7709dcca5d1b0c125cc04f",
     "grade": true,
     "grade_id": "Task2_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST & AUTOGRADE CELL\n",
    "@run_unittest\n",
    "\n",
    "class test_task_2(unittest.TestCase):\n",
    "    def test_00(self): \n",
    "        eq(tX.shape, (4708, 1))\n",
    "    def test_01(self):    \n",
    "        eq(vX.shape, (1178, 1))\n",
    "    def test_02(self):\n",
    "        eq(tY.shape, (4708,))\n",
    "    def test_03(self):\n",
    "        eq(vY.shape, (1178,))\n",
    "    def test_04(self):\n",
    "        eq(tX.sum().values, 12249)\n",
    "    def test_05(self):\n",
    "        eq(vX.sum().values, 3047)\n",
    "    def test_06(self):\n",
    "        eq(tY.sum(), 2360)\n",
    "    def test_07(self):\n",
    "        eq(vY.sum(), 583)\n",
    "    def test_08(self):\n",
    "        eq(lr.get_params()['random_state'], 0)\n",
    "    def test_09(self):\n",
    "        aeq(lr.score(vX, vY), 0.6061120543293718, 2)  # validation accuracy. compare to 3 decimal places\n",
    "    def test_10(self):\n",
    "        aeq(lr.score(tX, tY), 0.6274426508071368, 2)  # training accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1d57f8329bd81716bb69fb25fff476a",
     "grade": false,
     "grade_id": "Task3_read",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Task 3. Add numeric feature: a count of consonants\n",
    "\n",
    "If vowel count was helpful, the model might also benefit from the count of consonant symbols in each name. This is just a hypothesis with no guarantees, but we can add this numeric feature, train and test our model to evaluate whether this feature is useful. Copy `df1` to the dataframe `df2` (containing now two features) and add `Consonants` column to `df2` with counts of letters `'bcdfghjklmnpqrstvwxz'` in each name.\n",
    "\n",
    "Here is an example of the top two rows of `df2`:\n",
    "\n",
    "|Name|Y|Vowels|Consonants|\n",
    "|-|-|-|-|\n",
    "|abagail|1|4|3|\n",
    "|abbe|1|2|2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89cb23289eac0ea83555a513c6c05b5a",
     "grade": false,
     "grade_id": "Task3_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "df2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba93ce7cac75d901b01a38c421a12f06",
     "grade": true,
     "grade_id": "Task3_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST & AUTOGRADE CELL\n",
    "@run_unittest\n",
    "\n",
    "class test_task_3(unittest.TestCase):\n",
    "    def test_00(self):    \n",
    "        assert 'Vowels' in df2\n",
    "    def test_01(self):\n",
    "        assert 'Consonants' in df2\n",
    "    def test_02(self):\n",
    "        eq(df2.shape, (5886, 3))    # df should contain only columns Y, Vowels, and Consonants\n",
    "    def test_03(self):\n",
    "        eq(df2.query(\"Name=='abagail'\").iloc[0,:].values, (1,4,3))\n",
    "    def test_04(self):\n",
    "        eq(df2.query(\"Name=='abbe'\").iloc[0,:].values, (1,2,2))\n",
    "    def test_05(self):\n",
    "        eq(df2.sum().values, [ 2943, 15296, 20066])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1baaf033d433df18a1d3c39e1ba47137",
     "grade": false,
     "grade_id": "Task4_read",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Task 4. Train and validate logistic regression with Consonants feature\n",
    " \n",
    "As before, split the new dataframe into `tX, vX, tY, vY`, then create a `LogisticRegression()` object, `lr`, fit it on the training inputs/outputs and validate it on the test inputs/outputs. Use the same function arguments as you did above in Task 2.\n",
    " \n",
    "If done correctly, the additional use of consonant counts should improve the model slightly with validation accuracy of 62% and training accuracy of 63%. Recall that we only care for validation accuracy, i.e. the model's performance on observations it has not used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68005510e93a6989ba2b3afe7a9bec87",
     "grade": false,
     "grade_id": "Task4_ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "lr.score(vX, vY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70e46a49aa425bc174a867e364618f41",
     "grade": true,
     "grade_id": "Task_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST & AUTOGRADE CELL\n",
    "@run_unittest\n",
    "\n",
    "class test_task_4(unittest.TestCase):\n",
    "    def test_00(self):    \n",
    "        eq(tX.shape, (4708, 2))\n",
    "    def test_01(self):\n",
    "        eq(vX.shape, (1178, 2))\n",
    "    def test_02(self):\n",
    "        eq(tY.shape, (4708,))\n",
    "    def test_03(self):\n",
    "        eq(vY.shape, (1178,))\n",
    "    def test_04(self):\n",
    "        eq(tX.sum().values, [12249, 15970])\n",
    "    def test_05(self):\n",
    "        eq(vX.sum().values, [3047, 4096])\n",
    "    def test_06(self):\n",
    "        eq(tY.sum(), 2360)\n",
    "    def test_07(self):\n",
    "        eq(vY.sum(), 583)\n",
    "    def test_08(self):\n",
    "        eq(lr.get_params()['random_state'], 0)\n",
    "    def test_09(self):\n",
    "        aeq(lr.score(vX, vY), 0.6230899830220713, 2)  # validation accuracy. compare to 3 decimal places\n",
    "    def test_10(self):\n",
    "        aeq(lr.score(tX, tY), 0.6285046728971962, 2)  # training accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5b452cabb794aa9910731583b16f164",
     "grade": false,
     "grade_id": "Practice_read",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Practice\n",
    " \n",
    "As an additional practice try adding more features to continue improving the model's predictive performance. For example, you can find the most frequent first letter among male names and among female names. Suppose, it turns out that male names in our sample `LsM` often start with a letter `'m'` and female names in the sample `LsF` often start with a letter `'f'`. We could add two individual features, such as `IsM` and `IsF`, which would indicate 0 for no match of the given letter and 1 for a match. Alternatively, we can add just one feature with a value -1 for letter `'m'`, 1 for letter `'f'` and 0 for no match. \n",
    " \n",
    "You might be surprised to find out that this feature does not improve the validation accuracy of our model. However, if you focus on the last character in the male and female names, then you will greatly succeed. \n",
    " \n",
    "While each of these hypothesis makes sense, the model improves only from the **incremental** value of each additional feature. So, while the first character indicator may be valuable on its own, it does not appear to improve the model built on `df2` with two features you have added earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#606366>\n",
    "    <details><summary><font color=crimson>▶ </font>See <b>solution</b>.</summary>\n",
    "        <b>Hint:</b>\n",
    "        <details><summary><font color=crimson>ᐅ </font>One more click for a <b>solution</b>.</summary>\n",
    "            <pre>\n",
    "df3 = df2.copy()\n",
    "sECF = Counter([s[0] for s in LsF]).most_common(1)[0][0]  # most common first letter among male names\n",
    "sECM = Counter([s[0] for s in LsM]).most_common(1)[0][0]  # most common first letter among female names\n",
    "sECF, sECM  # Length of the strings containing most common first letter\n",
    "df3['FirstChar'] = df3.reset_index().Name.apply(lambda s: 1 if s[0]=='m' else -1 if s[0]=='s' else 0).values\n",
    "df3 = df2.copy()\n",
    "Counter([s[-1] for s in LsF]).most_common(1)\n",
    "Counter([s[-1] for s in LsM]).most_common(1)\n",
    "df3['LastChar'] = df3.reset_index().Name.apply(lambda s: 1 if s[-1]=='n' else -1 if s[-1]=='a' else 0).values\n",
    "            </pre>\n",
    "        </details>\n",
    "    </details> \n",
    "</font>\n",
    " <hr>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
